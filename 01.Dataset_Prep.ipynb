{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identification of sustainability-focused campaigns on the kickstarter crowdfunding platform using NLP and ML boosted with swarm intelligence\n",
    "--- ------------------\n",
    "<div>\n",
    "Data Analysis: part 1\n",
    "<br>\n",
    "Submitted by: Jossin Antony<br>\n",
    "Affiliation: THU Ulm<br>\n",
    "Date: 11.06.2024\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- [Introduction]()\n",
    "- [Details of dataset]()\n",
    "- [Preparation of Dataset]()\n",
    "- [Save dataset]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Introduction\n",
    "--- -------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of the project is to study how crowdfunding campaigns support sustainable inititatives. This project, in particular, focuses on crowdfunded campaigns in the [kickstarter](https://www.kickstarter.com/) platform and explores a dataset of c.a 184,186 initiatives from different domains (e.g, Technology, Music, Publishing etc.). The goal of the analyses here is to find the most important features that are relevant to initiatives that are both sustainable as well as profitable. The analyses will also explore the possible relationship of the features with each other, and elucidate insights that might contribute to better understanding of the success/failure propsects of current and future environment focused crowdfunded initiatives.\n",
    "\n",
    "\n",
    "#### B. Details of dataset:\n",
    "-- -------------------\n",
    "1. Source: [Kickstarter_File.xlsx](Kickstarter_File.xlsx)\n",
    "2. Generation mode: provided by researcher\n",
    "3. Time period considered: 04-2009 to 05-2021 (c.a 146 months).\n",
    "4. Total entries: 184,185\n",
    "\n",
    "The initial data preparation consists of examining the various features and eliminating redundant features & renaming and re-ordering of features and saving the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Preparation of Dataset\n",
    "--- ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we make sure the dataset is 'reasonable', i.e, it has good structure, columns have data of expected types, devoid of null values etc.\n",
    "\n",
    "The basic information of the data is as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the raw dataset from excel file. This is slow.\n",
    "df= pd.read_excel('./data/Kickstarter_File.xlsx')\n",
    "#--------------------------------------------------\n",
    "#write the raw dataset as a data frame in a csv file. Do this only once, if the dataframe file is not provided already.\n",
    "df.dropna(how='all', inplace=True)\n",
    "df.to_csv('./data/dataframe_raw.csv', index=False)\n",
    "#--------------------------------------------------\n",
    "#load the raw dataset from the data frame csv file, ONCE file is already created. This is fast as compared to reading from excel file.\n",
    "#df= pd.read_csv('./data/dataframe_raw.csv', low_memory=False)\n",
    "#df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has 184187 rows and 11 columns.\n",
      "\n",
      "The overall dataframe information is given below:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 184187 entries, 0 to 1048574\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   campaign_name       184186 non-null  object \n",
      " 1   blurb               184184 non-null  object \n",
      " 2   main_category       176465 non-null  object \n",
      " 3   sub_category        184186 non-null  object \n",
      " 4   is_environmental    2053 non-null    object \n",
      " 5   is_social           2053 non-null    object \n",
      " 6   country             184186 non-null  object \n",
      " 7   duration_in_days    184186 non-null  float64\n",
      " 8   goal_usd            184186 non-null  float64\n",
      " 9   pledged_amount_usd  184186 non-null  float64\n",
      " 10  is_success          184186 non-null  object \n",
      "dtypes: float64(3), object(8)\n",
      "memory usage: 16.9+ MB\n",
      "None\n",
      "\n",
      "We also make the preliminary observation that the columns named 'environmental', 'social' and 'unnamed: 5' have lots of 'NaN' values. We will deal with them later.\n"
     ]
    }
   ],
   "source": [
    "df.rename_axis('index',inplace=True)\n",
    "shape= df.shape\n",
    "print(f'The dataframe has {shape[0]} rows and {shape[1]} columns.')\n",
    "print()\n",
    "print('The overall dataframe information is given below:')\n",
    "print(df.info())\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"We also make the preliminary observation that the columns named 'environmental', 'social' and 'unnamed: 5' \\\n",
    "have lots of 'NaN' values. We will deal with them later.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_na=df[df.isna().sum(axis=1)>2]\n",
    "rows_na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we provide meaningful names to the columns to reflect the nature of the data they contain as well as re-order them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the columns to meaningful names\n",
    "df.rename(columns={'Environmental':'is_environmental',\n",
    "                   'Social':'is_social',\n",
    "                   'state':'is_success',\n",
    "                   'Unnamed: 5':'main_category',\n",
    "                   'Subcategory':'sub_category',\n",
    "                   'converted_pledged_amount':'pledged_amount_usd',\n",
    "                   'goal':'goal_in_local_currency',\n",
    "                   'duration':'duration_in_days',\n",
    "                   'name':'campaign_name',\n",
    "                   'pledged':'pledged_in_local_currency',\n",
    "                   },inplace=True)\n",
    "df.sample(2)\n",
    "#Reorder the columns\n",
    "print('column_names:',list(df.columns))\n",
    "df=df[['campaign_name', \n",
    "       'blurb', \n",
    "       'slug', \n",
    "       'main_category',\n",
    "       'sub_category', \n",
    "       'is_environmental', \n",
    "       'is_social', \n",
    "       'country', \n",
    "       'country_displayable_name', \n",
    "       'created_at', \n",
    "       'launched_at', \n",
    "       'deadline', \n",
    "       'duration_in_days', \n",
    "       'currency', \n",
    "       'goal_in_local_currency', \n",
    "       'pledged_in_local_currency', \n",
    "       'usd_pledged',\n",
    "       'pledged_amount_usd', \n",
    "       'staff_pick', \n",
    "       'state.1', \n",
    "       'fx_rate', \n",
    "       'static_usd_rate', \n",
    "       'usd_exchange_rate',\n",
    "       'is_success',]]\n",
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new column_names are:\n",
      " campaign_name\n",
      "blurb\n",
      "slug\n",
      "main_category\n",
      "sub_category\n",
      "is_environmental\n",
      "is_social\n",
      "country\n",
      "country_displayable_name\n",
      "created_at\n",
      "launched_at\n",
      "deadline\n",
      "duration_in_days\n",
      "currency\n",
      "goal_in_local_currency\n",
      "pledged_in_local_currency\n",
      "usd_pledged\n",
      "pledged_amount_usd\n",
      "staff_pick\n",
      "state.1\n",
      "fx_rate\n",
      "static_usd_rate\n",
      "usd_exchange_rate\n",
      "is_success\n"
     ]
    }
   ],
   "source": [
    "print('The new column_names are:\\n','\\n'.join(list(df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we drop the columns which are redundant or which do not add any value to the analysis. The dropped columns are as following:\n",
    "\n",
    "1. <b>'country' and 'country_displayable_name':</b>\n",
    "\n",
    "    We need only one of these; but we save the country codes for later reference.\n",
    "\n",
    "2. <b>'created_at', 'launched_at', 'deadline', 'duration':</b>\n",
    "\n",
    "    There is no discernible difference between 'created_at' and 'launched_at' since they are, at maximum, only few days apart in order to have an effect on the results we look for. 'duration' provides the difference in days between launched_at and deadline and we keep this parameter (for now).\n",
    "\n",
    "3. <b>'currency', 'goal_in_local_currency', 'pledged_in_local_currency', 'usd_pledged','converted_pledged_amount_usd', 'fx_rate', 'static_usd_rate', 'usd_exchange_rate':</b>\n",
    "\n",
    "    There is the goal- but only in local currency- and the pledged amount- in both local currency and usd. \n",
    "    We add a new column, 'goal_in_usd', which gives the goal in usd as well. It is obtained by multiplying the 'goal_in_local_currency' with the provided 'usd_exchange_rate' (Logic: The converted_pledged_amount_usd is provided by the author as a product of 'usd_exchange_rate' and 'pledged_in_local_currency').\n",
    "\n",
    "4. <b>'staff_pick' and 'state.1':</b>\n",
    "    These columns are dropped, since state.1 is a reptition of the column 'is_success' and 'staff_pick' do not seem to add value to the analysis at hand.\n",
    "\n",
    "5. <b>'slug' and 'campaign_name':</b>\n",
    "    'slug'is a repetition of 'campaign_name', it is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns which do not add value to the analysis\n",
    "#---------------------------------------------------\n",
    "#1. 'country' and 'country_displayable_name'.\n",
    "# We need only on of these; but save the country codes for later reference.\n",
    "df[['country_displayable_name','country']].drop_duplicates().reset_index(drop=True).to_csv('./data/country_codes.txt',sep='\\t', index=False),\n",
    "\n",
    "#---------------------------------------------------\n",
    "#2. 'created_at', 'launched_at', 'deadline', 'duration'\n",
    "# There is no discernible difference between created_at and launched_at since they are, at maximum, only few days apart in oorder to have an \n",
    "#effect on the results we look for. duration provides the difference in days between launched_at and deadline and we keep this parameter (for now).\n",
    "\n",
    "#-------------------------------------------------\n",
    "#3. 'currency', 'goal_in_local_currency', 'pledged_in_local_currency', 'usd_pledged', 'converted_pledged_amount_usd',\n",
    "# 'fx_rate', 'static_usd_rate', 'usd_exchange_rate'\n",
    "# There is the goal- but only in local currency- and the pledged amount- in both local currency and usd. \n",
    "# We add a new column, 'goal_in_usd', which gives the goal in usd as well. It is obtained by multiplying the 'goal_in_local_currency' with\n",
    "# the provided 'usd_exchange_rate' (Logic: The converted_pledged_amount_usd is provided by the author as a product of 'usd_exchange_rate' \n",
    "# and pledged_i'n_local_currency).\n",
    "df['goal_usd']= df['goal_in_local_currency']*df['usd_exchange_rate'] \n",
    "#We retain, in the end, 'goal_in_usd' and 'converted_pledged_amount_usd' and drop other currency, exchange rates and goal and pledged amounts\n",
    "#in local currency.\n",
    "\n",
    "#-------------------------------------------------\n",
    "#4. 'staff_pick' and 'state.1'\n",
    "# These columns are dropped, since state.1 is a reptition of the column 'is_success' and 'staff_pick' do not seem to add value to the \n",
    "#analysis at hand.\n",
    "\n",
    "#-------------------------------------------------\n",
    "#5. 'slug' and 'campaign_name'\n",
    "# 'slug'is a repetition of 'campaign_name', it is dropped.\n",
    "\n",
    "#-------------------------------------------------\n",
    "#Drop unwanted columns\n",
    "columns_to_drop= ['country_displayable_name', \n",
    "       'slug',\n",
    "       'created_at', \n",
    "       'launched_at', \n",
    "       'deadline', \n",
    "       'currency', \n",
    "       'goal_in_local_currency', \n",
    "       'pledged_in_local_currency', \n",
    "       'usd_pledged',\n",
    "       'staff_pick', \n",
    "       'state.1', \n",
    "       'fx_rate', \n",
    "       'static_usd_rate', \n",
    "       'usd_exchange_rate',]\n",
    "for column in columns_to_drop:\n",
    "       if column in df.columns:\n",
    "              df.drop(column, axis=1, inplace=True)\n",
    "\n",
    "#-------------------------------------------------\n",
    "#Reorder columns\n",
    "print('column_names:',list(df.columns))\n",
    "df=df[['campaign_name', \n",
    "       'blurb',\n",
    "       'main_category', \n",
    "       'sub_category', \n",
    "       'is_environmental', \n",
    "       'is_social', \n",
    "       'country', \n",
    "       'duration_in_days', \n",
    "       'goal_usd',\n",
    "       'pledged_amount_usd', \n",
    "       'is_success', \n",
    "       ]]\n",
    "#Round floating number values to 2\n",
    "df=df.round(2)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of the selected features:\n",
      " campaign_name\n",
      "blurb\n",
      "main_category\n",
      "sub_category\n",
      "is_environmental\n",
      "is_social\n",
      "country\n",
      "duration_in_days\n",
      "goal_usd\n",
      "pledged_amount_usd\n",
      "is_success\n"
     ]
    }
   ],
   "source": [
    "print('Overview of the selected features:\\n','\\n'.join(list(df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Save dataset\n",
    "--- -------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this we save the data to a local file for the next set of analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the processed data\n",
    "df.dropna(how='all', inplace=True)\n",
    "df.to_csv('./data/dataframe_stripped_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 01.Dataset_Prep.ipynb to webpdf\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 65479 bytes to 01.Dataset_Prep.pdf\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-2' coro=<Connection.run() running at C:\\Users\\Ronin\\miniforge3\\envs\\dl4cv\\Lib\\site-packages\\playwright\\_impl\\_connection.py:274> wait_for=<Future pending cb=[Task.task_wakeup()]>>\n",
      "Exception ignored in: <function BaseSubprocessTransport.__del__ at 0x000002397A25C220>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronin\\miniforge3\\envs\\dl4cv\\Lib\\asyncio\\base_subprocess.py\", line 126, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\Ronin\\miniforge3\\envs\\dl4cv\\Lib\\asyncio\\base_subprocess.py\", line 104, in close\n",
      "    proto.pipe.close()\n",
      "  File \"C:\\Users\\Ronin\\miniforge3\\envs\\dl4cv\\Lib\\asyncio\\proactor_events.py\", line 109, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\Ronin\\miniforge3\\envs\\dl4cv\\Lib\\asyncio\\base_events.py\", line 793, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\Ronin\\miniforge3\\envs\\dl4cv\\Lib\\asyncio\\base_events.py\", line 540, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Exception ignored in: <function _ProactorBasePipeTransport.__del__ at 0x000002397A25DA80>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronin\\miniforge3\\envs\\dl4cv\\Lib\\asyncio\\proactor_events.py\", line 116, in __del__\n",
      "    _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "                               ^^^^^^^^\n",
      "  File \"C:\\Users\\Ronin\\miniforge3\\envs\\dl4cv\\Lib\\asyncio\\proactor_events.py\", line 80, in __repr__\n",
      "    info.append(f'fd={self._sock.fileno()}')\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Ronin\\miniforge3\\envs\\dl4cv\\Lib\\asyncio\\windows_utils.py\", line 102, in fileno\n",
      "    raise ValueError(\"I/O operation on closed pipe\")\n",
      "ValueError: I/O operation on closed pipe\n",
      "Exception ignored in: <function _ProactorBasePipeTransport.__del__ at 0x000002397A25DA80>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronin\\miniforge3\\envs\\dl4cv\\Lib\\asyncio\\proactor_events.py\", line 116, in __del__\n",
      "    _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "                               ^^^^^^^^\n",
      "  File \"C:\\Users\\Ronin\\miniforge3\\envs\\dl4cv\\Lib\\asyncio\\proactor_events.py\", line 80, in __repr__\n",
      "    info.append(f'fd={self._sock.fileno()}')\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Ronin\\miniforge3\\envs\\dl4cv\\Lib\\asyncio\\windows_utils.py\", line 102, in fileno\n",
      "    raise ValueError(\"I/O operation on closed pipe\")\n",
      "ValueError: I/O operation on closed pipe\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to webpdf 01.Dataset_Prep.ipynb --no-input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
