{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identification of sustainability-focused campaigns on the kickstarter crowdfunding platform using NLP and ML boosted with swarm intelligence\n",
    "--- ------------------\n",
    "<div>\n",
    "Data Analysis: part 2\n",
    "<br>\n",
    "Submitted by: Jossin Antony<br>\n",
    "Affiliation: THU Ulm<br>\n",
    "Date: 11.06.2024\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- [Introduction]()\n",
    "- [Extraction of key words]()\n",
    "- [Attention!]()\n",
    "- [To Dos]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Introduction\n",
    "--- -------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue our analysis with the filtered dataset from part 1. The data set consists of features 'is_environmental' and 'is_social' which are thought to be very essential in the upcoming analyses. However, only 1% of these columns hold values. \n",
    "In this script, we try to populate the rest of the columns with values using NLP analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.feature_extraction.text as text\n",
    "import sklearn.naive_bayes as nb\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score\n",
    "\n",
    "from pprint import PrettyPrinter\n",
    "pp= PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "df= pd.read_csv('./data/dataframe_stripped_features.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We print 2 random rows of the dataset for preliminary impressions.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign_name</th>\n",
       "      <th>blurb</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>is_environmental</th>\n",
       "      <th>is_social</th>\n",
       "      <th>country</th>\n",
       "      <th>duration_in_days</th>\n",
       "      <th>goal_usd</th>\n",
       "      <th>pledged_amount_usd</th>\n",
       "      <th>is_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13946</th>\n",
       "      <td>Enchanted Woods Lenormand Oracle Deck</td>\n",
       "      <td>A hand illustrated Lenormand tarot/oracle deck...</td>\n",
       "      <td>Art</td>\n",
       "      <td>Illustration</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>2880.0</td>\n",
       "      <td>successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30689</th>\n",
       "      <td>The Black-Jack Demon</td>\n",
       "      <td>To avenge his father's unnatural murder, Silas...</td>\n",
       "      <td>Comics</td>\n",
       "      <td>Comic Books</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>32.74</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>successful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               campaign_name  \\\n",
       "13946  Enchanted Woods Lenormand Oracle Deck   \n",
       "30689                   The Black-Jack Demon   \n",
       "\n",
       "                                                   blurb main_category  \\\n",
       "13946  A hand illustrated Lenormand tarot/oracle deck...          Art    \n",
       "30689  To avenge his father's unnatural murder, Silas...       Comics    \n",
       "\n",
       "         sub_category is_environmental is_social country  duration_in_days  \\\n",
       "13946   Illustration               NaN       NaN      US             30.00   \n",
       "30689    Comic Books               NaN       NaN      US             32.74   \n",
       "\n",
       "       goal_usd  pledged_amount_usd  is_success  \n",
       "13946    1300.0              2880.0  successful  \n",
       "30689    3000.0              3436.0  successful  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('We print 2 random rows of the dataset for preliminary impressions.')\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "df.sample(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['funding_acquired_percent']=((df['pledged_amount_usd']/df['goal_usd'])*100).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df[df['goal_usd']>=1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139608"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df[df['funding_acquired_percent'] >=50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78447"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "funding_acquired_percent\n",
       "39595.0    1\n",
       "39182.0    1\n",
       "36554.0    1\n",
       "35537.0    1\n",
       "31959.0    1\n",
       "31202.0    1\n",
       "30912.0    1\n",
       "30665.0    1\n",
       "25600.0    1\n",
       "24729.0    1\n",
       "23866.0    1\n",
       "21742.0    1\n",
       "18575.0    1\n",
       "18483.0    1\n",
       "18294.0    1\n",
       "17965.0    1\n",
       "17950.0    1\n",
       "17587.0    1\n",
       "17071.0    1\n",
       "17031.0    1\n",
       "16973.0    1\n",
       "16870.0    1\n",
       "16641.0    1\n",
       "15867.0    1\n",
       "15620.0    1\n",
       "15618.0    1\n",
       "15537.0    1\n",
       "15342.0    1\n",
       "15251.0    1\n",
       "15099.0    1\n",
       "15007.0    1\n",
       "14927.0    1\n",
       "14705.0    1\n",
       "14322.0    1\n",
       "14070.0    1\n",
       "14044.0    1\n",
       "13908.0    1\n",
       "13812.0    1\n",
       "13776.0    1\n",
       "13501.0    1\n",
       "13456.0    1\n",
       "12905.0    1\n",
       "12902.0    1\n",
       "12848.0    1\n",
       "12838.0    1\n",
       "12756.0    1\n",
       "12750.0    1\n",
       "12200.0    1\n",
       "12194.0    1\n",
       "12081.0    1\n",
       "11714.0    1\n",
       "11442.0    1\n",
       "11307.0    1\n",
       "11217.0    1\n",
       "11103.0    1\n",
       "11047.0    1\n",
       "10998.0    1\n",
       "10973.0    1\n",
       "10844.0    1\n",
       "10668.0    1\n",
       "10641.0    1\n",
       "10635.0    1\n",
       "10541.0    1\n",
       "10514.0    1\n",
       "10477.0    1\n",
       "10465.0    1\n",
       "10425.0    1\n",
       "10402.0    1\n",
       "10384.0    1\n",
       "10381.0    1\n",
       "10196.0    1\n",
       "10138.0    1\n",
       "10113.0    1\n",
       "9859.0     1\n",
       "9811.0     1\n",
       "9768.0     1\n",
       "9764.0     1\n",
       "9664.0     1\n",
       "9651.0     1\n",
       "9597.0     1\n",
       "9581.0     1\n",
       "9444.0     1\n",
       "9324.0     1\n",
       "9277.0     1\n",
       "9252.0     1\n",
       "9185.0     1\n",
       "8942.0     1\n",
       "8879.0     1\n",
       "8763.0     1\n",
       "8760.0     1\n",
       "8665.0     1\n",
       "8649.0     1\n",
       "8584.0     1\n",
       "8576.0     1\n",
       "8569.0     1\n",
       "8536.0     1\n",
       "8481.0     1\n",
       "8405.0     1\n",
       "8380.0     1\n",
       "8378.0     1\n",
       "8281.0     2\n",
       "8252.0     1\n",
       "8211.0     1\n",
       "8149.0     1\n",
       "8138.0     1\n",
       "8074.0     1\n",
       "7928.0     1\n",
       "7897.0     1\n",
       "7881.0     1\n",
       "7874.0     1\n",
       "7860.0     1\n",
       "7851.0     2\n",
       "7814.0     1\n",
       "7685.0     1\n",
       "7684.0     1\n",
       "7631.0     1\n",
       "7526.0     1\n",
       "7520.0     1\n",
       "7514.0     1\n",
       "7486.0     1\n",
       "7470.0     1\n",
       "7461.0     1\n",
       "7430.0     1\n",
       "7419.0     1\n",
       "7417.0     1\n",
       "7409.0     1\n",
       "7406.0     1\n",
       "7404.0     1\n",
       "7400.0     1\n",
       "7378.0     1\n",
       "7377.0     1\n",
       "7376.0     1\n",
       "7333.0     1\n",
       "7319.0     1\n",
       "7310.0     1\n",
       "7301.0     1\n",
       "7236.0     1\n",
       "7185.0     2\n",
       "7130.0     1\n",
       "7054.0     1\n",
       "7012.0     1\n",
       "7008.0     1\n",
       "6978.0     1\n",
       "6969.0     1\n",
       "6910.0     1\n",
       "6803.0     1\n",
       "6792.0     1\n",
       "6779.0     1\n",
       "6759.0     1\n",
       "6758.0     1\n",
       "6752.0     1\n",
       "6749.0     1\n",
       "6713.0     1\n",
       "6673.0     1\n",
       "6653.0     1\n",
       "6605.0     1\n",
       "6578.0     1\n",
       "6569.0     1\n",
       "6567.0     1\n",
       "6546.0     1\n",
       "6540.0     1\n",
       "6533.0     1\n",
       "6439.0     1\n",
       "6350.0     1\n",
       "6327.0     1\n",
       "6326.0     1\n",
       "6279.0     1\n",
       "6264.0     2\n",
       "6255.0     1\n",
       "6247.0     1\n",
       "6241.0     1\n",
       "6240.0     1\n",
       "6221.0     1\n",
       "6189.0     1\n",
       "6185.0     1\n",
       "6164.0     1\n",
       "6124.0     1\n",
       "6116.0     1\n",
       "6110.0     1\n",
       "6107.0     1\n",
       "6103.0     2\n",
       "6087.0     1\n",
       "6019.0     1\n",
       "5990.0     1\n",
       "5964.0     1\n",
       "5954.0     1\n",
       "5928.0     1\n",
       "5917.0     2\n",
       "5913.0     1\n",
       "5905.0     1\n",
       "5897.0     1\n",
       "5888.0     1\n",
       "5879.0     1\n",
       "5852.0     1\n",
       "5826.0     1\n",
       "5808.0     1\n",
       "5800.0     1\n",
       "5785.0     1\n",
       "5777.0     1\n",
       "5766.0     1\n",
       "5758.0     1\n",
       "5737.0     1\n",
       "5715.0     1\n",
       "5681.0     1\n",
       "5680.0     1\n",
       "5665.0     1\n",
       "5613.0     1\n",
       "5609.0     1\n",
       "5606.0     1\n",
       "5589.0     1\n",
       "5575.0     1\n",
       "5570.0     1\n",
       "5519.0     1\n",
       "5511.0     1\n",
       "5482.0     1\n",
       "5473.0     1\n",
       "5471.0     1\n",
       "5468.0     1\n",
       "5463.0     1\n",
       "5456.0     1\n",
       "5445.0     1\n",
       "5417.0     1\n",
       "5403.0     1\n",
       "5393.0     1\n",
       "5330.0     1\n",
       "5310.0     1\n",
       "5301.0     1\n",
       "5290.0     1\n",
       "5245.0     1\n",
       "5243.0     1\n",
       "5242.0     1\n",
       "5223.0     1\n",
       "5221.0     1\n",
       "5218.0     1\n",
       "5206.0     1\n",
       "5171.0     1\n",
       "5162.0     1\n",
       "5156.0     1\n",
       "5146.0     1\n",
       "5142.0     1\n",
       "5136.0     1\n",
       "5129.0     1\n",
       "5117.0     1\n",
       "5113.0     1\n",
       "5112.0     1\n",
       "5084.0     1\n",
       "5066.0     1\n",
       "5055.0     1\n",
       "5038.0     1\n",
       "5030.0     2\n",
       "5024.0     1\n",
       "5016.0     1\n",
       "5004.0     1\n",
       "4944.0     1\n",
       "4905.0     1\n",
       "4875.0     1\n",
       "4825.0     1\n",
       "4815.0     1\n",
       "4776.0     1\n",
       "4762.0     1\n",
       "4744.0     1\n",
       "4723.0     1\n",
       "4714.0     1\n",
       "4710.0     1\n",
       "4707.0     1\n",
       "4697.0     1\n",
       "4642.0     1\n",
       "4635.0     1\n",
       "4632.0     1\n",
       "4620.0     1\n",
       "4607.0     1\n",
       "4600.0     1\n",
       "4595.0     1\n",
       "4586.0     1\n",
       "4559.0     1\n",
       "4554.0     1\n",
       "4538.0     1\n",
       "4527.0     2\n",
       "4513.0     1\n",
       "4496.0     1\n",
       "4493.0     1\n",
       "4485.0     1\n",
       "4479.0     1\n",
       "4474.0     1\n",
       "4449.0     1\n",
       "4443.0     1\n",
       "4431.0     1\n",
       "4428.0     1\n",
       "4417.0     1\n",
       "4385.0     1\n",
       "4378.0     1\n",
       "4374.0     1\n",
       "4368.0     1\n",
       "4365.0     1\n",
       "4364.0     1\n",
       "4362.0     1\n",
       "4353.0     1\n",
       "4351.0     1\n",
       "4349.0     1\n",
       "4342.0     1\n",
       "4338.0     1\n",
       "4336.0     1\n",
       "4317.0     3\n",
       "4316.0     1\n",
       "4289.0     1\n",
       "4278.0     1\n",
       "4265.0     1\n",
       "4246.0     1\n",
       "4244.0     2\n",
       "4220.0     1\n",
       "4219.0     1\n",
       "4208.0     1\n",
       "4171.0     2\n",
       "4144.0     1\n",
       "4143.0     1\n",
       "4140.0     1\n",
       "4136.0     1\n",
       "4132.0     1\n",
       "4128.0     1\n",
       "4124.0     1\n",
       "4113.0     1\n",
       "4110.0     1\n",
       "4084.0     1\n",
       "4068.0     1\n",
       "4061.0     1\n",
       "4060.0     1\n",
       "4053.0     1\n",
       "4048.0     1\n",
       "4047.0     1\n",
       "4039.0     1\n",
       "4033.0     1\n",
       "4031.0     2\n",
       "4024.0     1\n",
       "4010.0     2\n",
       "4004.0     1\n",
       "3943.0     2\n",
       "3939.0     1\n",
       "3937.0     1\n",
       "3921.0     1\n",
       "3911.0     1\n",
       "3909.0     1\n",
       "3905.0     1\n",
       "3897.0     1\n",
       "3893.0     1\n",
       "3880.0     1\n",
       "3872.0     1\n",
       "3871.0     1\n",
       "3865.0     1\n",
       "3848.0     1\n",
       "3847.0     1\n",
       "3841.0     1\n",
       "3835.0     1\n",
       "3826.0     1\n",
       "3823.0     1\n",
       "3820.0     1\n",
       "3814.0     1\n",
       "3805.0     1\n",
       "3799.0     1\n",
       "3796.0     1\n",
       "3775.0     1\n",
       "3768.0     1\n",
       "3732.0     1\n",
       "3723.0     1\n",
       "3722.0     1\n",
       "3718.0     1\n",
       "3699.0     1\n",
       "3690.0     1\n",
       "3682.0     1\n",
       "3680.0     1\n",
       "3663.0     1\n",
       "3661.0     1\n",
       "3660.0     2\n",
       "3655.0     1\n",
       "3651.0     1\n",
       "3643.0     3\n",
       "3642.0     1\n",
       "3633.0     1\n",
       "3628.0     1\n",
       "3624.0     1\n",
       "3621.0     1\n",
       "3614.0     1\n",
       "3613.0     1\n",
       "3603.0     1\n",
       "3591.0     1\n",
       "3590.0     2\n",
       "3589.0     1\n",
       "3588.0     1\n",
       "3582.0     2\n",
       "3563.0     1\n",
       "3557.0     1\n",
       "3556.0     1\n",
       "3551.0     1\n",
       "3548.0     1\n",
       "3542.0     1\n",
       "3540.0     2\n",
       "3538.0     2\n",
       "3533.0     1\n",
       "3531.0     1\n",
       "3529.0     1\n",
       "3524.0     1\n",
       "3518.0     1\n",
       "3517.0     1\n",
       "3511.0     1\n",
       "3508.0     1\n",
       "3504.0     1\n",
       "3503.0     1\n",
       "3495.0     1\n",
       "3494.0     1\n",
       "3490.0     1\n",
       "3478.0     2\n",
       "3474.0     1\n",
       "3467.0     1\n",
       "3461.0     1\n",
       "3456.0     1\n",
       "3447.0     1\n",
       "3446.0     1\n",
       "3445.0     1\n",
       "3442.0     1\n",
       "3437.0     1\n",
       "3435.0     1\n",
       "3433.0     1\n",
       "3403.0     1\n",
       "3401.0     1\n",
       "3394.0     1\n",
       "3392.0     1\n",
       "3391.0     1\n",
       "3390.0     1\n",
       "3387.0     1\n",
       "3386.0     2\n",
       "3377.0     1\n",
       "3374.0     1\n",
       "3371.0     1\n",
       "3355.0     2\n",
       "3345.0     1\n",
       "3340.0     1\n",
       "3332.0     1\n",
       "3326.0     1\n",
       "3325.0     1\n",
       "3323.0     1\n",
       "3322.0     1\n",
       "3320.0     1\n",
       "3319.0     2\n",
       "3318.0     1\n",
       "3314.0     1\n",
       "3307.0     1\n",
       "3300.0     1\n",
       "3294.0     1\n",
       "3293.0     1\n",
       "3279.0     1\n",
       "3270.0     1\n",
       "3267.0     1\n",
       "3263.0     2\n",
       "3261.0     1\n",
       "3258.0     1\n",
       "3246.0     2\n",
       "3242.0     1\n",
       "3240.0     1\n",
       "3239.0     1\n",
       "3228.0     2\n",
       "3222.0     1\n",
       "3217.0     1\n",
       "3209.0     1\n",
       "3204.0     1\n",
       "3201.0     1\n",
       "3194.0     1\n",
       "3186.0     1\n",
       "3182.0     1\n",
       "3180.0     2\n",
       "3176.0     1\n",
       "3161.0     1\n",
       "3152.0     4\n",
       "3150.0     1\n",
       "3142.0     1\n",
       "3139.0     2\n",
       "3135.0     1\n",
       "3133.0     1\n",
       "3129.0     1\n",
       "3125.0     1\n",
       "3117.0     1\n",
       "3116.0     1\n",
       "3114.0     2\n",
       "3105.0     1\n",
       "3096.0     1\n",
       "3095.0     1\n",
       "3094.0     2\n",
       "3082.0     1\n",
       "3080.0     1\n",
       "3073.0     1\n",
       "3070.0     1\n",
       "3069.0     1\n",
       "3067.0     2\n",
       "3064.0     1\n",
       "3057.0     1\n",
       "3046.0     1\n",
       "3036.0     1\n",
       "3032.0     1\n",
       "3031.0     1\n",
       "3025.0     1\n",
       "3018.0     1\n",
       "3016.0     1\n",
       "3008.0     1\n",
       "3000.0     1\n",
       "2998.0     1\n",
       "2997.0     1\n",
       "2996.0     1\n",
       "2992.0     1\n",
       "2979.0     1\n",
       "2978.0     1\n",
       "2973.0     1\n",
       "2969.0     1\n",
       "2966.0     1\n",
       "2951.0     2\n",
       "2950.0     1\n",
       "2948.0     2\n",
       "2941.0     1\n",
       "2938.0     1\n",
       "2936.0     1\n",
       "2935.0     3\n",
       "2922.0     1\n",
       "2916.0     3\n",
       "2910.0     1\n",
       "2904.0     1\n",
       "2894.0     1\n",
       "2887.0     1\n",
       "2886.0     1\n",
       "2884.0     2\n",
       "2880.0     2\n",
       "2879.0     1\n",
       "2878.0     2\n",
       "2877.0     1\n",
       "2873.0     1\n",
       "2872.0     1\n",
       "2870.0     1\n",
       "2868.0     1\n",
       "2865.0     1\n",
       "2856.0     1\n",
       "2852.0     1\n",
       "2851.0     1\n",
       "2845.0     1\n",
       "2842.0     1\n",
       "2840.0     1\n",
       "2828.0     2\n",
       "2827.0     1\n",
       "2814.0     1\n",
       "2805.0     1\n",
       "2803.0     2\n",
       "2798.0     1\n",
       "2791.0     2\n",
       "2787.0     2\n",
       "2783.0     1\n",
       "2782.0     1\n",
       "2779.0     1\n",
       "2774.0     1\n",
       "2769.0     1\n",
       "2761.0     1\n",
       "2753.0     1\n",
       "2752.0     1\n",
       "2751.0     1\n",
       "2747.0     1\n",
       "2746.0     1\n",
       "2745.0     1\n",
       "2741.0     2\n",
       "2740.0     2\n",
       "2737.0     1\n",
       "2729.0     1\n",
       "2725.0     1\n",
       "2722.0     2\n",
       "2715.0     1\n",
       "2708.0     1\n",
       "2701.0     3\n",
       "2698.0     1\n",
       "2697.0     1\n",
       "2692.0     1\n",
       "2691.0     2\n",
       "2688.0     1\n",
       "2681.0     1\n",
       "2680.0     1\n",
       "2677.0     1\n",
       "2673.0     1\n",
       "2672.0     1\n",
       "2671.0     1\n",
       "2663.0     3\n",
       "2662.0     1\n",
       "2656.0     1\n",
       "2655.0     2\n",
       "2652.0     1\n",
       "2650.0     1\n",
       "2649.0     2\n",
       "2648.0     1\n",
       "2646.0     1\n",
       "2644.0     1\n",
       "2637.0     1\n",
       "2626.0     1\n",
       "2624.0     1\n",
       "2623.0     1\n",
       "2622.0     1\n",
       "2621.0     1\n",
       "2620.0     1\n",
       "2614.0     1\n",
       "2607.0     1\n",
       "2591.0     1\n",
       "2590.0     1\n",
       "2588.0     1\n",
       "2587.0     1\n",
       "2585.0     3\n",
       "2584.0     1\n",
       "2582.0     2\n",
       "2573.0     2\n",
       "2570.0     1\n",
       "2565.0     1\n",
       "2563.0     1\n",
       "2555.0     1\n",
       "2550.0     1\n",
       "2549.0     1\n",
       "2548.0     1\n",
       "2547.0     2\n",
       "2546.0     1\n",
       "2545.0     1\n",
       "2544.0     1\n",
       "2539.0     1\n",
       "2537.0     1\n",
       "2534.0     1\n",
       "2533.0     1\n",
       "2531.0     1\n",
       "2530.0     1\n",
       "2529.0     2\n",
       "2526.0     1\n",
       "2524.0     1\n",
       "2521.0     2\n",
       "2519.0     1\n",
       "2516.0     1\n",
       "2508.0     2\n",
       "2507.0     1\n",
       "2503.0     1\n",
       "2501.0     1\n",
       "2498.0     1\n",
       "2497.0     1\n",
       "2496.0     1\n",
       "2489.0     1\n",
       "2484.0     1\n",
       "2483.0     1\n",
       "2481.0     1\n",
       "2480.0     1\n",
       "2472.0     1\n",
       "2468.0     1\n",
       "2465.0     1\n",
       "2464.0     1\n",
       "2463.0     1\n",
       "2461.0     2\n",
       "2455.0     2\n",
       "2454.0     2\n",
       "2452.0     1\n",
       "2446.0     2\n",
       "2441.0     1\n",
       "2439.0     1\n",
       "2437.0     2\n",
       "2436.0     1\n",
       "2435.0     1\n",
       "2433.0     1\n",
       "2431.0     1\n",
       "2427.0     1\n",
       "2426.0     1\n",
       "2420.0     2\n",
       "2415.0     1\n",
       "2412.0     1\n",
       "2410.0     1\n",
       "2408.0     1\n",
       "2406.0     1\n",
       "2401.0     1\n",
       "2398.0     1\n",
       "2396.0     1\n",
       "2393.0     1\n",
       "2387.0     1\n",
       "2384.0     2\n",
       "2383.0     1\n",
       "2380.0     1\n",
       "2376.0     2\n",
       "2374.0     2\n",
       "2372.0     1\n",
       "2365.0     1\n",
       "2361.0     1\n",
       "2360.0     1\n",
       "2354.0     1\n",
       "2346.0     1\n",
       "2344.0     2\n",
       "2342.0     1\n",
       "2335.0     1\n",
       "2332.0     1\n",
       "2331.0     1\n",
       "2329.0     1\n",
       "2328.0     1\n",
       "2321.0     1\n",
       "2318.0     1\n",
       "2314.0     1\n",
       "2313.0     1\n",
       "2307.0     1\n",
       "2305.0     1\n",
       "2303.0     1\n",
       "2302.0     1\n",
       "2299.0     1\n",
       "2298.0     2\n",
       "2297.0     2\n",
       "2296.0     1\n",
       "2295.0     2\n",
       "2290.0     1\n",
       "2289.0     1\n",
       "2288.0     2\n",
       "2286.0     2\n",
       "2285.0     2\n",
       "2275.0     2\n",
       "2272.0     1\n",
       "2270.0     1\n",
       "2269.0     1\n",
       "2267.0     1\n",
       "2266.0     1\n",
       "2262.0     1\n",
       "2253.0     1\n",
       "2252.0     1\n",
       "2251.0     1\n",
       "2250.0     1\n",
       "2248.0     1\n",
       "2247.0     1\n",
       "2246.0     2\n",
       "2244.0     1\n",
       "2242.0     1\n",
       "2240.0     1\n",
       "2239.0     2\n",
       "2236.0     2\n",
       "2235.0     1\n",
       "2232.0     1\n",
       "2223.0     1\n",
       "2222.0     3\n",
       "2218.0     1\n",
       "2217.0     1\n",
       "2216.0     1\n",
       "2215.0     2\n",
       "2213.0     3\n",
       "2212.0     1\n",
       "2211.0     1\n",
       "2207.0     2\n",
       "2206.0     1\n",
       "2205.0     2\n",
       "2203.0     1\n",
       "2201.0     3\n",
       "2198.0     2\n",
       "2195.0     1\n",
       "2194.0     1\n",
       "2190.0     1\n",
       "2178.0     1\n",
       "2177.0     2\n",
       "2174.0     2\n",
       "2172.0     1\n",
       "2171.0     2\n",
       "2163.0     1\n",
       "2159.0     1\n",
       "2158.0     1\n",
       "2156.0     4\n",
       "2152.0     2\n",
       "2151.0     1\n",
       "2149.0     1\n",
       "2147.0     2\n",
       "2143.0     3\n",
       "2139.0     1\n",
       "2137.0     2\n",
       "2121.0     1\n",
       "2118.0     2\n",
       "2117.0     1\n",
       "2115.0     1\n",
       "2113.0     1\n",
       "2112.0     2\n",
       "2111.0     2\n",
       "2106.0     2\n",
       "2105.0     1\n",
       "2100.0     1\n",
       "2092.0     1\n",
       "2089.0     1\n",
       "2088.0     1\n",
       "2085.0     1\n",
       "2084.0     1\n",
       "2082.0     1\n",
       "2079.0     1\n",
       "2070.0     1\n",
       "2069.0     1\n",
       "2068.0     3\n",
       "2064.0     1\n",
       "2063.0     1\n",
       "2061.0     1\n",
       "2058.0     2\n",
       "2056.0     2\n",
       "2052.0     1\n",
       "2050.0     1\n",
       "2043.0     3\n",
       "2041.0     2\n",
       "2040.0     2\n",
       "2037.0     2\n",
       "2036.0     2\n",
       "2035.0     1\n",
       "2026.0     1\n",
       "2024.0     1\n",
       "2023.0     1\n",
       "2019.0     2\n",
       "2018.0     1\n",
       "2017.0     1\n",
       "2014.0     1\n",
       "2007.0     3\n",
       "2006.0     1\n",
       "2005.0     1\n",
       "2003.0     1\n",
       "2001.0     1\n",
       "2000.0     1\n",
       "1996.0     1\n",
       "1994.0     1\n",
       "1993.0     1\n",
       "1990.0     1\n",
       "1989.0     1\n",
       "1987.0     1\n",
       "1984.0     2\n",
       "1980.0     1\n",
       "1973.0     1\n",
       "1972.0     2\n",
       "1971.0     1\n",
       "1970.0     1\n",
       "1969.0     1\n",
       "1962.0     2\n",
       "1961.0     2\n",
       "1958.0     2\n",
       "1956.0     1\n",
       "1955.0     1\n",
       "1954.0     1\n",
       "1951.0     1\n",
       "1950.0     1\n",
       "1949.0     3\n",
       "1948.0     3\n",
       "1947.0     1\n",
       "1946.0     1\n",
       "1945.0     5\n",
       "1944.0     1\n",
       "1938.0     1\n",
       "1933.0     1\n",
       "1931.0     1\n",
       "1930.0     1\n",
       "1929.0     1\n",
       "1928.0     1\n",
       "1925.0     2\n",
       "1924.0     1\n",
       "1919.0     1\n",
       "1917.0     1\n",
       "1916.0     1\n",
       "1915.0     1\n",
       "1913.0     1\n",
       "1912.0     1\n",
       "1909.0     2\n",
       "1907.0     2\n",
       "1906.0     1\n",
       "1905.0     1\n",
       "1904.0     1\n",
       "1903.0     1\n",
       "1899.0     2\n",
       "1894.0     2\n",
       "1891.0     1\n",
       "1888.0     3\n",
       "1887.0     2\n",
       "1886.0     1\n",
       "1885.0     1\n",
       "1882.0     2\n",
       "1879.0     2\n",
       "1874.0     2\n",
       "1873.0     1\n",
       "1871.0     1\n",
       "1869.0     1\n",
       "1865.0     1\n",
       "1864.0     1\n",
       "1863.0     1\n",
       "1862.0     2\n",
       "1860.0     3\n",
       "1854.0     1\n",
       "1849.0     1\n",
       "1846.0     1\n",
       "1845.0     2\n",
       "1844.0     2\n",
       "1843.0     1\n",
       "1840.0     2\n",
       "1839.0     1\n",
       "1838.0     1\n",
       "1835.0     1\n",
       "1833.0     1\n",
       "1831.0     2\n",
       "1830.0     1\n",
       "1827.0     1\n",
       "1825.0     1\n",
       "1824.0     1\n",
       "1823.0     1\n",
       "1822.0     1\n",
       "1820.0     2\n",
       "1817.0     1\n",
       "1815.0     3\n",
       "1814.0     1\n",
       "1811.0     2\n",
       "1809.0     2\n",
       "1807.0     1\n",
       "1806.0     1\n",
       "1805.0     1\n",
       "1804.0     1\n",
       "1799.0     1\n",
       "1798.0     1\n",
       "1797.0     1\n",
       "1795.0     1\n",
       "1794.0     1\n",
       "1793.0     2\n",
       "1792.0     1\n",
       "1791.0     2\n",
       "1789.0     1\n",
       "1788.0     1\n",
       "1786.0     3\n",
       "1784.0     1\n",
       "1783.0     1\n",
       "1780.0     1\n",
       "1773.0     1\n",
       "1772.0     1\n",
       "1770.0     1\n",
       "1763.0     1\n",
       "1761.0     1\n",
       "1760.0     1\n",
       "1758.0     1\n",
       "1754.0     1\n",
       "1752.0     2\n",
       "1751.0     1\n",
       "1750.0     2\n",
       "1749.0     1\n",
       "1747.0     1\n",
       "1746.0     1\n",
       "1744.0     2\n",
       "1740.0     2\n",
       "1739.0     3\n",
       "1738.0     2\n",
       "1737.0     4\n",
       "1736.0     3\n",
       "1735.0     1\n",
       "1734.0     1\n",
       "1733.0     1\n",
       "1732.0     2\n",
       "1730.0     1\n",
       "1729.0     1\n",
       "1725.0     1\n",
       "1724.0     1\n",
       "1722.0     1\n",
       "1721.0     2\n",
       "1720.0     1\n",
       "1719.0     2\n",
       "1718.0     1\n",
       "1715.0     4\n",
       "1714.0     3\n",
       "1712.0     1\n",
       "1711.0     2\n",
       "1710.0     2\n",
       "1707.0     1\n",
       "1705.0     1\n",
       "1704.0     1\n",
       "1703.0     1\n",
       "1698.0     1\n",
       "1697.0     1\n",
       "1696.0     3\n",
       "1694.0     3\n",
       "1692.0     2\n",
       "1689.0     2\n",
       "1688.0     4\n",
       "1686.0     1\n",
       "1684.0     1\n",
       "1682.0     1\n",
       "1681.0     1\n",
       "1680.0     2\n",
       "1678.0     2\n",
       "1677.0     1\n",
       "1676.0     1\n",
       "1674.0     1\n",
       "1671.0     1\n",
       "1669.0     1\n",
       "1667.0     2\n",
       "1666.0     1\n",
       "1665.0     2\n",
       "1663.0     1\n",
       "1662.0     1\n",
       "1661.0     1\n",
       "1659.0     1\n",
       "1657.0     1\n",
       "1654.0     2\n",
       "1653.0     1\n",
       "1651.0     2\n",
       "1650.0     2\n",
       "1646.0     1\n",
       "1645.0     2\n",
       "1642.0     1\n",
       "1641.0     5\n",
       "1639.0     1\n",
       "1638.0     3\n",
       "1637.0     1\n",
       "1636.0     1\n",
       "1635.0     4\n",
       "1634.0     1\n",
       "1632.0     2\n",
       "1631.0     1\n",
       "1629.0     3\n",
       "1628.0     3\n",
       "1627.0     1\n",
       "1626.0     2\n",
       "1625.0     1\n",
       "1623.0     2\n",
       "1618.0     2\n",
       "1616.0     1\n",
       "1614.0     1\n",
       "1613.0     1\n",
       "1611.0     2\n",
       "1610.0     2\n",
       "1608.0     1\n",
       "1606.0     1\n",
       "1605.0     2\n",
       "1604.0     1\n",
       "1601.0     2\n",
       "1600.0     2\n",
       "1598.0     1\n",
       "1596.0     1\n",
       "1595.0     2\n",
       "1592.0     2\n",
       "1591.0     1\n",
       "1590.0     2\n",
       "1588.0     2\n",
       "1587.0     1\n",
       "1584.0     2\n",
       "1583.0     4\n",
       "1582.0     3\n",
       "1581.0     1\n",
       "1580.0     2\n",
       "1579.0     1\n",
       "1577.0     2\n",
       "1574.0     1\n",
       "1573.0     1\n",
       "1572.0     1\n",
       "1570.0     3\n",
       "1569.0     3\n",
       "1568.0     1\n",
       "1566.0     2\n",
       "1561.0     2\n",
       "1560.0     2\n",
       "1558.0     2\n",
       "1557.0     2\n",
       "1556.0     1\n",
       "1555.0     1\n",
       "1553.0     2\n",
       "1552.0     2\n",
       "1551.0     1\n",
       "1549.0     4\n",
       "1548.0     1\n",
       "1546.0     1\n",
       "1545.0     1\n",
       "1544.0     2\n",
       "1543.0     1\n",
       "1541.0     1\n",
       "1539.0     1\n",
       "1538.0     1\n",
       "1535.0     1\n",
       "1533.0     1\n",
       "1532.0     3\n",
       "1531.0     1\n",
       "1530.0     1\n",
       "1529.0     2\n",
       "1528.0     1\n",
       "1526.0     1\n",
       "1523.0     2\n",
       "1522.0     2\n",
       "1521.0     3\n",
       "1519.0     1\n",
       "1518.0     2\n",
       "1517.0     1\n",
       "1515.0     3\n",
       "1514.0     2\n",
       "1513.0     1\n",
       "1510.0     1\n",
       "1509.0     4\n",
       "1508.0     2\n",
       "1507.0     2\n",
       "1505.0     3\n",
       "1504.0     2\n",
       "1502.0     1\n",
       "1501.0     1\n",
       "1500.0     1\n",
       "1499.0     3\n",
       "1497.0     1\n",
       "1495.0     1\n",
       "1494.0     1\n",
       "1493.0     3\n",
       "1492.0     2\n",
       "1491.0     1\n",
       "1489.0     2\n",
       "1486.0     1\n",
       "1485.0     2\n",
       "1482.0     3\n",
       "1479.0     3\n",
       "1478.0     1\n",
       "1477.0     4\n",
       "1476.0     1\n",
       "1475.0     2\n",
       "1473.0     1\n",
       "1472.0     1\n",
       "1471.0     1\n",
       "1470.0     2\n",
       "1469.0     3\n",
       "1467.0     2\n",
       "1466.0     1\n",
       "1465.0     2\n",
       "1463.0     1\n",
       "1462.0     4\n",
       "1461.0     2\n",
       "1460.0     1\n",
       "1459.0     1\n",
       "1457.0     1\n",
       "1456.0     1\n",
       "1455.0     1\n",
       "1454.0     1\n",
       "1453.0     2\n",
       "1451.0     5\n",
       "1449.0     1\n",
       "1448.0     1\n",
       "1447.0     1\n",
       "1446.0     1\n",
       "1444.0     1\n",
       "1443.0     2\n",
       "1442.0     1\n",
       "1441.0     1\n",
       "1439.0     2\n",
       "1438.0     2\n",
       "1437.0     3\n",
       "1436.0     1\n",
       "1434.0     1\n",
       "1433.0     1\n",
       "1431.0     3\n",
       "1429.0     3\n",
       "1428.0     2\n",
       "1427.0     2\n",
       "1426.0     1\n",
       "1425.0     2\n",
       "1423.0     2\n",
       "1422.0     1\n",
       "1421.0     4\n",
       "1420.0     2\n",
       "1418.0     1\n",
       "1417.0     3\n",
       "1416.0     1\n",
       "1415.0     2\n",
       "1414.0     2\n",
       "1413.0     1\n",
       "1412.0     1\n",
       "1410.0     2\n",
       "1406.0     2\n",
       "1405.0     2\n",
       "1403.0     2\n",
       "1402.0     2\n",
       "1401.0     1\n",
       "1400.0     1\n",
       "1399.0     1\n",
       "1398.0     1\n",
       "1397.0     2\n",
       "1396.0     1\n",
       "1395.0     1\n",
       "1394.0     1\n",
       "1393.0     3\n",
       "1389.0     1\n",
       "1388.0     1\n",
       "1385.0     1\n",
       "1384.0     4\n",
       "1382.0     2\n",
       "1380.0     2\n",
       "1379.0     1\n",
       "1378.0     1\n",
       "1377.0     4\n",
       "1375.0     1\n",
       "1374.0     2\n",
       "1373.0     4\n",
       "1372.0     1\n",
       "1371.0     2\n",
       "1369.0     1\n",
       "1368.0     1\n",
       "1367.0     1\n",
       "1366.0     1\n",
       "1365.0     1\n",
       "1364.0     1\n",
       "1363.0     4\n",
       "1362.0     3\n",
       "1361.0     1\n",
       "1360.0     1\n",
       "1359.0     2\n",
       "1358.0     1\n",
       "1357.0     2\n",
       "1354.0     1\n",
       "1353.0     3\n",
       "1352.0     2\n",
       "1351.0     2\n",
       "1350.0     1\n",
       "1349.0     2\n",
       "1348.0     1\n",
       "1347.0     1\n",
       "1346.0     1\n",
       "1345.0     1\n",
       "1344.0     4\n",
       "1342.0     2\n",
       "1341.0     3\n",
       "1340.0     2\n",
       "1339.0     1\n",
       "1338.0     1\n",
       "1336.0     3\n",
       "1335.0     1\n",
       "1334.0     1\n",
       "1333.0     1\n",
       "1332.0     4\n",
       "1331.0     2\n",
       "1330.0     1\n",
       "1329.0     2\n",
       "1328.0     2\n",
       "1326.0     2\n",
       "1325.0     2\n",
       "1324.0     1\n",
       "1323.0     2\n",
       "1322.0     1\n",
       "1321.0     2\n",
       "1320.0     2\n",
       "1319.0     1\n",
       "1318.0     1\n",
       "1316.0     1\n",
       "1315.0     1\n",
       "1312.0     1\n",
       "1311.0     2\n",
       "1310.0     2\n",
       "1308.0     2\n",
       "1307.0     3\n",
       "1305.0     2\n",
       "1302.0     2\n",
       "1301.0     5\n",
       "1300.0     2\n",
       "1298.0     2\n",
       "1297.0     3\n",
       "1294.0     1\n",
       "1292.0     3\n",
       "1291.0     3\n",
       "1290.0     2\n",
       "1289.0     1\n",
       "1288.0     4\n",
       "1287.0     3\n",
       "1286.0     2\n",
       "1285.0     1\n",
       "1284.0     5\n",
       "1283.0     2\n",
       "1282.0     1\n",
       "1281.0     1\n",
       "1280.0     1\n",
       "1279.0     2\n",
       "1278.0     2\n",
       "1276.0     1\n",
       "1273.0     2\n",
       "1271.0     1\n",
       "1270.0     2\n",
       "1269.0     1\n",
       "1267.0     1\n",
       "1266.0     1\n",
       "1265.0     3\n",
       "1264.0     1\n",
       "1262.0     1\n",
       "1261.0     4\n",
       "1260.0     4\n",
       "1259.0     1\n",
       "1258.0     1\n",
       "1257.0     1\n",
       "1256.0     3\n",
       "1255.0     2\n",
       "1254.0     3\n",
       "1253.0     4\n",
       "1249.0     3\n",
       "1248.0     2\n",
       "1246.0     2\n",
       "1245.0     1\n",
       "1244.0     1\n",
       "1243.0     2\n",
       "1242.0     1\n",
       "1241.0     1\n",
       "1240.0     1\n",
       "1236.0     3\n",
       "1235.0     1\n",
       "1233.0     1\n",
       "1231.0     1\n",
       "1229.0     1\n",
       "1228.0     4\n",
       "1226.0     3\n",
       "1225.0     1\n",
       "1224.0     2\n",
       "1223.0     1\n",
       "1222.0     3\n",
       "1221.0     4\n",
       "1220.0     2\n",
       "1219.0     1\n",
       "1218.0     1\n",
       "1217.0     1\n",
       "1216.0     3\n",
       "1215.0     3\n",
       "1214.0     3\n",
       "1213.0     1\n",
       "1212.0     3\n",
       "1211.0     1\n",
       "1210.0     3\n",
       "1209.0     2\n",
       "1207.0     1\n",
       "1206.0     4\n",
       "1205.0     2\n",
       "1204.0     1\n",
       "1202.0     3\n",
       "1201.0     1\n",
       "1200.0     4\n",
       "1199.0     1\n",
       "1198.0     3\n",
       "1197.0     3\n",
       "1196.0     1\n",
       "1195.0     2\n",
       "1194.0     2\n",
       "1193.0     3\n",
       "1192.0     2\n",
       "1191.0     1\n",
       "1189.0     2\n",
       "1188.0     2\n",
       "1187.0     3\n",
       "1186.0     1\n",
       "1185.0     3\n",
       "1184.0     2\n",
       "1183.0     3\n",
       "1182.0     2\n",
       "1181.0     2\n",
       "1179.0     1\n",
       "1178.0     3\n",
       "1177.0     2\n",
       "1174.0     1\n",
       "1173.0     2\n",
       "1172.0     1\n",
       "1170.0     2\n",
       "1169.0     2\n",
       "1168.0     1\n",
       "1167.0     3\n",
       "1166.0     2\n",
       "1165.0     1\n",
       "1164.0     3\n",
       "1163.0     1\n",
       "1162.0     1\n",
       "1161.0     4\n",
       "1160.0     2\n",
       "1159.0     1\n",
       "1158.0     1\n",
       "1157.0     3\n",
       "1156.0     4\n",
       "1155.0     2\n",
       "1153.0     4\n",
       "1152.0     1\n",
       "1151.0     1\n",
       "1149.0     2\n",
       "1148.0     1\n",
       "1147.0     4\n",
       "1146.0     2\n",
       "1145.0     3\n",
       "1144.0     2\n",
       "1143.0     3\n",
       "1142.0     2\n",
       "1141.0     1\n",
       "1140.0     1\n",
       "1139.0     3\n",
       "1138.0     2\n",
       "1137.0     3\n",
       "1136.0     2\n",
       "1135.0     1\n",
       "1134.0     3\n",
       "1133.0     2\n",
       "1132.0     3\n",
       "1131.0     1\n",
       "1130.0     2\n",
       "1129.0     1\n",
       "1128.0     3\n",
       "1126.0     2\n",
       "1125.0     3\n",
       "1124.0     1\n",
       "1123.0     3\n",
       "1122.0     1\n",
       "1121.0     5\n",
       "1120.0     3\n",
       "1118.0     2\n",
       "1117.0     2\n",
       "1116.0     1\n",
       "1115.0     6\n",
       "1114.0     2\n",
       "1113.0     1\n",
       "1112.0     2\n",
       "1111.0     1\n",
       "1110.0     4\n",
       "1109.0     4\n",
       "1108.0     3\n",
       "1107.0     4\n",
       "1106.0     4\n",
       "1105.0     1\n",
       "1103.0     2\n",
       "1102.0     3\n",
       "1101.0     3\n",
       "1100.0     6\n",
       "1099.0     1\n",
       "1098.0     3\n",
       "1097.0     4\n",
       "1096.0     2\n",
       "1095.0     1\n",
       "1094.0     1\n",
       "1093.0     1\n",
       "1092.0     3\n",
       "1091.0     3\n",
       "1090.0     2\n",
       "1089.0     1\n",
       "1088.0     1\n",
       "1087.0     4\n",
       "1086.0     3\n",
       "1084.0     1\n",
       "1082.0     4\n",
       "1080.0     4\n",
       "1079.0     1\n",
       "1078.0     2\n",
       "1077.0     1\n",
       "1076.0     1\n",
       "1075.0     2\n",
       "1074.0     1\n",
       "1073.0     2\n",
       "1071.0     1\n",
       "1070.0     3\n",
       "1069.0     1\n",
       "1067.0     1\n",
       "1066.0     4\n",
       "1065.0     2\n",
       "1064.0     7\n",
       "1063.0     2\n",
       "1062.0     1\n",
       "1060.0     1\n",
       "1059.0     1\n",
       "1058.0     4\n",
       "1057.0     2\n",
       "1056.0     1\n",
       "1055.0     1\n",
       "1054.0     1\n",
       "1053.0     2\n",
       "1052.0     4\n",
       "1051.0     2\n",
       "1049.0     2\n",
       "1048.0     1\n",
       "1047.0     1\n",
       "1046.0     2\n",
       "1045.0     4\n",
       "1043.0     3\n",
       "1042.0     4\n",
       "1041.0     1\n",
       "1040.0     2\n",
       "1039.0     1\n",
       "1038.0     1\n",
       "1037.0     1\n",
       "1036.0     2\n",
       "1035.0     2\n",
       "1034.0     3\n",
       "1032.0     8\n",
       "1031.0     4\n",
       "1030.0     2\n",
       "1029.0     3\n",
       "1028.0     4\n",
       "1027.0     5\n",
       "1026.0     4\n",
       "1025.0     1\n",
       "1024.0     4\n",
       "1023.0     3\n",
       "1022.0     1\n",
       "1020.0     2\n",
       "1019.0     2\n",
       "1018.0     6\n",
       "1017.0     2\n",
       "1016.0     4\n",
       "1015.0     4\n",
       "1014.0     1\n",
       "1013.0     4\n",
       "1012.0     6\n",
       "1011.0     4\n",
       "1010.0     3\n",
       "1008.0     2\n",
       "1007.0     5\n",
       "1006.0     6\n",
       "1005.0     3\n",
       "1004.0     3\n",
       "1003.0     1\n",
       "1002.0     3\n",
       "1001.0     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df[df['funding_acquired_percent']>1000]['funding_acquired_percent'].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "campaign_name               4812\n",
       "blurb                       4812\n",
       "main_category               4812\n",
       "sub_category                4812\n",
       "is_environmental              54\n",
       "is_social                     54\n",
       "country                     4812\n",
       "duration_in_days            4812\n",
       "goal_usd                    4812\n",
       "pledged_amount_usd          4812\n",
       "is_success                  4812\n",
       "funding_acquired_percent    4812\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['funding_acquired_percent']>500].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration_in_days']= np.ceil(df['duration_in_days']/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration_in_days\n",
       "1.0    47252\n",
       "2.0    30221\n",
       "3.0      943\n",
       "4.0       30\n",
       "5.0        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['duration_in_days'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "campaign_name                                                 blurb                                                                                                                                    main_category  sub_category  is_environmental  is_social  country  duration_in_days  goal_usd  pledged_amount_usd  is_success  funding_acquired_percent\n",
       "Star Wars Toy Guide: Vol 1 - Kenner Action Figures 1977-1985  An in-depth guide to the original Kenner line                                                                                            Publishing     Art Books     No                No         GB       2.0               171735.8  193335.0            successful  113.0                       1\n",
       "Lightseekers                                                  A next generation adventure role playing video game connecting smart action figures, trading cards, & comics in ways never seen before.  Games          Video Games   No                No         US       1.0               200000.0  227660.0            successful  114.0                       1\n",
       "Chronicles of Elyria - Epic Story MMORPG with Aging & Death   Dynamic & immersive MMORPG where your character ages & dies in a fully destructible world with non-repeatable quests.                    Games          Video Games   No                No         US       2.0               900000.0  1361435.0           successful  151.0                       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['goal_usd']>170000].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Extraction of key words\n",
    "--- -------------------\n",
    "\n",
    "We try to extract the main keywords which will help to classify the blurbs- description of the project-  as environmentally or socially relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the data are manually curated and classified as socially or environmentally relevant. We start with the analysis of this data in the hopes that it might reveal some clues to understand how the data was actually classified, beyond the human notions of what is socially or environmentally relevant.\n",
    "\n",
    "First we replace all the NaN values with the term 'unspecified'. Next we check how many samples were manually curated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: The Dataset has 1944 rows with an \"Yes\" or \"No\" value in \"is_environment\" and \"is_social\" columns.\n",
      "Note: Due to manual curation all the selected samples have values in both \"is_environmental\" and \"is_social\" columns.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fill the fields with NaN as 'unspecified'\n",
    "df = df.fillna('unspecified')\n",
    "\n",
    "# Extract the samples having values in 'is_environmental' and 'is_social' columns\n",
    "df_is_envt_or_social= df[((df['is_environmental']!='unspecified')) &\n",
    "                           ((df['is_social']!='unspecified'))]\n",
    "\n",
    "df_is_envt_or_social=df_is_envt_or_social[['campaign_name','blurb','is_environmental', 'is_social']]\n",
    "\n",
    "print(f'Observation: The Dataset has {df_is_envt_or_social.shape[0]} rows with an \"Yes\" or \"No\" value in \"is_environment\" and \"is_social\" columns.\\n\\\n",
    "Note: Due to manual curation all the selected samples have values in both \"is_environmental\" and \"is_social\" columns.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we check the proportion of 'yes' and 'No' values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_environmental\n",
      "No     1903\n",
      "Yes      41\n",
      "Name: count, dtype: int64\n",
      "is_social\n",
      "No     1918\n",
      "Yes      26\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check if the classes are balanced\n",
    "print(df_is_envt_or_social['is_environmental'].value_counts())\n",
    "print(df_is_envt_or_social['is_social'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The classes are not well balanced. We see that an overwhelming number of samples are classified 'NO' for social or environmental relevance. Classical classification machine learnings cannot be applied here, because the 'null accuracy' (prediction 'No') is well over 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an alternate (and easy) approach, we try to find the most important words that appear in the 'blurb' classified as socially/environmentally relevant. \n",
    "\n",
    "We start with the ['tf-idf'](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) algorithm. The aim is to calculate the mean tf-idf scores of the words that appear in the corpus marked as socially or environmentlly relevant and later attempt to use the appearance of these words to classify uncategorized extracts.\n",
    "\n",
    "Note:\n",
    "- We use [stemming](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html) to find the 'root' form of the words that appear in the corpus. We start the analysis with [snowball stemming](https://www.ibm.com/topics/stemming#Types+of+stemming+algorithms).\n",
    "- The [stopwords in english](https://gist.github.com/sebleier/554280) (e.g. 'and', 'these') are omitted from the analysis. Similarly, all numbers, symbols etc. are also ignored (e.g: 'covid-19' -> 'covid').\n",
    "- To increase the amount of training data, the 'campaign_name' is also considered along with 'blurb'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Easy test: tf-idf\n",
    "# tf-idf \n",
    "#STOP_WORDS='english'\n",
    "STOP_WORDS = list(text.ENGLISH_STOP_WORDS.union([str(i) for i in range(10)]))\n",
    "MIN_DOCS= .05\n",
    "TOKEN_PATTERN= '(?u)\\\\b[a-zA-Z]{2,}\\\\b'\n",
    "\n",
    "def stem(extract):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    return [' '.join([stemmer.stem(token) for token in word_tokenize(text)]) for text in extract]\n",
    "\n",
    "def transform_extract(extract):\n",
    "    return stem(re.sub(r'[\\W,]+', ' ', extract).replace('-', ' ').lower().split())\n",
    "\n",
    "def rank_words(df, ranked_words, column_affirmative, column_ranked_words='ranked_words', threshold=0.05):\n",
    "    df[column_affirmative] = 0\n",
    "    df['combined_description']=''\n",
    "    \n",
    "    df.loc[:,'combined_description'] = df.loc[:,'campaign_name'] + ' ' + df.loc[:,'blurb']\n",
    "\n",
    "    df.loc[:,column_ranked_words] = df.loc[:,'combined_description'].apply(\n",
    "        lambda blurb: [word if word in ranked_words.index and ranked_words.loc[word] > threshold else '' \n",
    "                        for word in transform_extract(blurb)]\n",
    "                        ).apply(lambda x: list(filter(None, x)))\n",
    "    \n",
    "    df.loc[:,column_affirmative]= df.loc[:,column_ranked_words].apply(len)\n",
    "    df.drop(columns=['combined_description'], axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_word_count_in_classified_blurbs(df, count_column):\n",
    "    return df[count_column].apply(lambda x: 'No keyword' if x == 0 else 'at least one keyword').value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of identified top words distinguising environmentally relevant blurbs: 33.\n",
      "\n",
      "The first column represents the relevant words and the second column gives the mean tf-idf score\n",
      "Note: The word are in the stemmed format. e.g \"sustain\" can mean \"sustainability\", \"sustaining\", \"sustained\" etc.\n",
      "\n",
      "Top words (is_environmental)\n",
      "-----------------------------\n",
      "sustain      0.146818\n",
      "organ        0.121158\n",
      "natur        0.084267\n",
      "friend        0.07456\n",
      "design        0.07273\n",
      "eco          0.069532\n",
      "food         0.060402\n",
      "build        0.060103\n",
      "recycl       0.058756\n",
      "farm          0.05819\n",
      "make         0.057818\n",
      "world        0.057185\n",
      "healthi      0.055094\n",
      "use           0.04879\n",
      "produc       0.048043\n",
      "small        0.046716\n",
      "save         0.045356\n",
      "fashion      0.044635\n",
      "local          0.0441\n",
      "provid       0.042886\n",
      "anim         0.042846\n",
      "compani      0.042332\n",
      "communiti    0.041974\n",
      "hand         0.040683\n",
      "awar         0.040172\n",
      "rais         0.040172\n",
      "vegan        0.040008\n",
      "mobil        0.039819\n",
      "project       0.03176\n",
      "creat        0.029823\n",
      "innov        0.028855\n",
      "materi       0.028556\n",
      "brand        0.027432\n",
      "dtype: Sparse[float64, 0]\n"
     ]
    }
   ],
   "source": [
    "#1. FInd top ranking words in samples classified as environmental\n",
    "#----------------------------------------------------------------\n",
    "tf_idf_model = TfidfVectorizer(stop_words=STOP_WORDS, min_df= MIN_DOCS, token_pattern=TOKEN_PATTERN)\n",
    "\n",
    "#blurb_is_environmental= df_is_envt_or_social[df_is_envt_or_social['is_environmental'] == 'Yes']['blurb'].tolist()\n",
    "blurb_is_environmental = df_is_envt_or_social[df_is_envt_or_social['is_environmental'] == 'Yes'][['campaign_name', 'blurb']].agg(' '.join, axis=1).tolist()\n",
    "blurb_is_environmental = stem([text.lower() for text in blurb_is_environmental])\n",
    "\n",
    "#Vectorization of corpus\n",
    "tf_idf_vector = tf_idf_model.fit_transform(blurb_is_environmental)\n",
    "\n",
    "# #Get original terms in the corpus\n",
    "words_set = tf_idf_model.get_feature_names_out()\n",
    "\n",
    "# #Data frame to show the TF-IDF scores of each document\n",
    "df_tf_idf = pd.DataFrame.sparse.from_spmatrix(tf_idf_vector, columns=words_set)\n",
    "\n",
    "# Calculate the sum of TF-IDF scores for each word\n",
    "word_importance = df_tf_idf.mean(axis=0)\n",
    "\n",
    "# Sort words based on the sum of TF-IDF scores\n",
    "ranked_words_environmental = word_importance.sort_values(ascending=False)\n",
    "\n",
    "# Print the ranked words\n",
    "print(f'''No. of identified top words distinguising environmentally relevant blurbs: {len(ranked_words_environmental)}.\\n\n",
    "The first column represents the relevant words and the second column gives the mean tf-idf score''')\n",
    "print('Note: The word are in the stemmed format. e.g \"sustain\" can mean \"sustainability\", \"sustaining\", \"sustained\" etc.')\n",
    "print()\n",
    "print('Top words (is_environmental)')\n",
    "print('-----------------------------')\n",
    "print(ranked_words_environmental)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we verify that this approach works! We expect that the words we found as relevant occur multiple times (atleast one time) in the samples manually curated as relevant and do not occur at all if they were manually curated as irrelevant. From this data we calculate the accuracy as the number of correctly classified/ total classified.\n",
    "\n",
    "We try this approach first on the samples marked as 'environmentally' relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorization summary\n",
      "========================\n",
      "yes_count: is_envt\n",
      "at least one keyword    36\n",
      "No keyword               5\n",
      "Name: count, dtype: int64\n",
      "accuracy: 0.8780\n"
     ]
    }
   ],
   "source": [
    "df_envt= df_is_envt_or_social[df_is_envt_or_social['is_environmental']=='Yes'].copy()\n",
    "df_envt.drop(columns=['is_social'],axis=1,inplace=True)\n",
    "rank_words(df_envt, ranked_words_environmental, column_affirmative='yes_count: is_envt',threshold=0.052)\n",
    "word_count_classified_envt= get_word_count_in_classified_blurbs(df_envt,'yes_count: is_envt' )\n",
    "print('Categorization summary')\n",
    "print('========================')\n",
    "print(word_count_classified_envt)\n",
    "print(f'accuracy: {word_count_classified_envt.iloc[0]/(word_count_classified_envt.iloc[0]+word_count_classified_envt.iloc[1]):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "Out of the 43 samples available, 36 were classified correctly and 7 incoorectly, giving us an accuracy of ~83%.\n",
    "We can also inspect the data frame in detail, so that we know where the results were false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign_name</th>\n",
       "      <th>blurb</th>\n",
       "      <th>is_environmental</th>\n",
       "      <th>yes_count: is_envt</th>\n",
       "      <th>ranked_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Beluga tent 6-in-1 from Qaou</td>\n",
       "      <td>The first all in one highly eco-friendly tent made from recycled plastic.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>[eco, friend, recycl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Thé-tis Tea : Plant-based seaweed tea, rich in minerals</td>\n",
       "      <td>Delicious tea infusion made with seaweed. Healthy, organic, plant-based, eco-friendly, and rich-mineral tea for vegans.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>[healthi, organ, eco, friend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>baby food</td>\n",
       "      <td>Inspired by the selection at the Grocery mart, I want to make Safe Healthy Nutritious Slurpable foods for baby. No preservatives added.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>[food, make, healthi, food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Chique Addiction</td>\n",
       "      <td>High fashions made from ethical and sustainable, environmentally friendly, vegan fabrics for the modern world.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>[sustain, friend, world]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Hearth &amp; Market - Wood Fired Food Truck &amp; Mobile Market</td>\n",
       "      <td>A wood fired food truck &amp; mobile farmers market that connects you to our farm, way of life and certified organic produce and products.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>[food, food, farm, organ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Sutra (Thread)Hand Dyed Hand Spinned Sustainable Yarn</td>\n",
       "      <td>To create yarn&amp;projects out of sustainable bamboo&amp;hemp fiber with the desert dye cochineal.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>[sustain, sustain]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Rebel Swim - Men's swim shorts, designed with a purpose!</td>\n",
       "      <td>Buy a pair of our beautiful men's swim shorts and protect an endangered animal!</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>[design]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Ash Apothecary: Small Batch, All-Natural Simple Syrup</td>\n",
       "      <td>Small-batch simple syrups for bartending, mixology, coffee, cocktails, soda, chai, and more. Only organic and non-GMO ingredients.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>[natur, organ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>Pawstively Droolicious</td>\n",
       "      <td>An all natural and homemade dog treats that are personalized to every dog's needs and desires.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>[natur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Stitchmill Clothing //  The Perfect Henley Shirt</td>\n",
       "      <td>Redefining Henley fashion for women and men. Sustainably making the highest quality Henleys in the U.S.A. Be You. Be Confident.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>[sustain, make]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Tree Rally</td>\n",
       "      <td>A David and Goliath story about a Sydney community fighting to save hundreds of heritage trees from government-funded destruction.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Organic agriculture against desertification: the book.</td>\n",
       "      <td>A tool for a better farming in semi arid regions, in the context of climate change and based on experience in a Permaculture project.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>[organ, farm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>Greenr</td>\n",
       "      <td>A company that tracks green behavior and rewards people with prizes in an effort to make the world a greener place!</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>[make, world]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>Diving Deep</td>\n",
       "      <td>Irrepressible underwater filmmaker Mike deGruy was adamant that we are destroying the ocean before we've discovered all that's there.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>Join the Blue Revolution</td>\n",
       "      <td>Through education, sustainable agriculture and getting our hands dirty, we will work to build a better world together!</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>[sustain, build, world]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>Longwater Community Farm</td>\n",
       "      <td>Growing our own food, caring for animals and the environment, providing education on healthy and sustainable living is what we do best!</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>[farm, food, healthi, sustain]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>Stinger Surf</td>\n",
       "      <td>Stinger Surf Co. is an innovative brand that makes eco-friendly surf products and gives back to save the bees.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>[make, eco, friend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>A NEW EXCITING ELECTRIC BICYCLE BRAND IN NORTH AMERICA</td>\n",
       "      <td>Darrvin is an innovative e-bike design and build company, delivering exquisite hand-build precision and superior quality</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>[design, build, build]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>Eco Bin the worlds first Eco Friendly Sanitary/Nappy bin</td>\n",
       "      <td>Worlds first Eco friendly Sanitary Bin that is biodegradable and 50% cheaper than a normal service provider.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>[eco, world, eco, friend, world, eco, friend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>OS eBike: Open Source Electric Bicycle Design You Can Build</td>\n",
       "      <td>A guide for making a lightweight eBike design built with open source hardware and software you assemble and customize yourself.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>[design, build, make, design]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>\"The Sun Juicer\"  Ultralight Parabolic Solar Cooker</td>\n",
       "      <td>A sustainable fuel free, clean energy, 0 emissions way of cooking that is great for your backyard, camping, emergencies, and fun!</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>[sustain]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>Boulder Denim 3.0: Active jeans for work, play, and everyday</td>\n",
       "      <td>Performance denim unlike anything you've worn before. Stretch, durability, breathability, and sustainability meet for the first time.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>[sustain]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>TEA BAR- Vegan and Eco-Friendly health bar flavored with tea</td>\n",
       "      <td>Organic, non-GMO, Eco-Friendly, Healthy, Super Food, Tasty, Vegan, Paleo, Keto.\\nCreated by a Chef and a Barista.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>[eco, friend, organ, eco, friend, healthi, food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>Sustainable Produce For The Locals, Annually</td>\n",
       "      <td>A self-sustaining farm to feed locals fresh organic produce year round. Aquaponic system powered by wind and recycles all materials.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>[sustain, sustain, farm, organ, recycl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>Fable: From Farm to Table</td>\n",
       "      <td>Fable aims to be a year-round source for the freshest produce, all grown locally and without the use of GMOs or harmful pesticides.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>[farm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>Low Cost Fresh &amp; Finished Organic Food</td>\n",
       "      <td>We are the First Vertical Integrated Organic Grower, Producer &amp; Distribution company in Central America exporting into the USA.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>[organ, food, organ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>Biobierwinkel</td>\n",
       "      <td>The first online 100% organic beer shop in the Netherlands. Bringing organic beers from small brewers from all over Europe to you.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>[organ, organ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>Ellice Ruiz | Girlfriend Tested, Mother Nature Approved</td>\n",
       "      <td>A sustainable &amp; ethical ready-to-wear collection for creative professionals that transitions from the studio to the show.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>[natur, sustain]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>SJ family farm and ranch organic community garden</td>\n",
       "      <td>The goal of SJ farms is to provide healthy organic produce to our surrounding communities. And  to create a healthier tomorrow.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>[farm, organ, farm, healthi, organ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>Recycle Scrap Paper into Building Material - Papercrete Brix</td>\n",
       "      <td>Everyone loves to recycle, this project is about recycling common ordinary paper into building materials or decorative plain old bricks</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>[recycl, build, recycl, recycl, build]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>@SpeedingDonuts +Donutruck</td>\n",
       "      <td>Bringing healthy and organic eating to donut lovers from a locally supported family business! #donuts @speedingdonuts</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>[healthi, organ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>Crude</td>\n",
       "      <td>A Campaign Film to raise awareness of the crude oil industry and the damage to the planet. Divest from oil.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>Young Scent - Premium Drinking Vinegar &amp; Vinegar Concentrate</td>\n",
       "      <td>All natural, handcrafted, organic fruit vinegars designed to vitalize your body.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>[natur, organ, design]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>PIVOT | The Spray Bottle Reinvented.</td>\n",
       "      <td>Effortlessly spray at any angle. Use every drop without priming.  Save the earth from \"disposable\" culture!</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>Animal-Friendly Footwear Made Using Apples.</td>\n",
       "      <td>Crafted in Europe using sustainable innovative materials. A tree planted with each pair made.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>[friend, sustain]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>Organic Soap that provides counseling for Foster children</td>\n",
       "      <td>Organic soap that gives back to children effected by foster care by providing counseling services.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>[organ, organ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>DIFFAIR | Eco-Friendly Swiss Designer Fashion</td>\n",
       "      <td>An exclusive collection of affordable and sustainable designer clothing from our new type of fashion brand / Exklusive Designkollektion</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>[eco, friend, design, sustain, design]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>Maushaus: Sustainable Desert Microdwelling</td>\n",
       "      <td>ASU Graduate Students must build a functional, sustainable mobile house of 100 square feet by May 1st!</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>[sustain, build, sustain]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>Endangered Animals: Africa Enamel Pin Series</td>\n",
       "      <td>A pin series raising awareness for endangered species.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>Tiny House From Recycled Seacontainers</td>\n",
       "      <td>Tiny Houses - Small mobile houses made from recycled seacontainers!</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>[recycl, recycl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>Brooklyn Artists + Nature + Tee Shirts = Brooklyn Tee Time</td>\n",
       "      <td>Roni &amp; Dawn Henning, Brooklyn Artists and Printmakers create a Tee shirt company to raise awareness about the natural world at risk</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>[natur, natur, world]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     campaign_name  \\\n",
       "47                                    Beluga tent 6-in-1 from Qaou   \n",
       "71         Thé-tis Tea : Plant-based seaweed tea, rich in minerals   \n",
       "99                                                       baby food   \n",
       "125                                               Chique Addiction   \n",
       "163        Hearth & Market - Wood Fired Food Truck & Mobile Market   \n",
       "170          Sutra (Thread)Hand Dyed Hand Spinned Sustainable Yarn   \n",
       "233       Rebel Swim - Men's swim shorts, designed with a purpose!   \n",
       "284          Ash Apothecary: Small Batch, All-Natural Simple Syrup   \n",
       "331                                         Pawstively Droolicious   \n",
       "351               Stitchmill Clothing //  The Perfect Henley Shirt   \n",
       "380                                                     Tree Rally   \n",
       "398         Organic agriculture against desertification: the book.   \n",
       "474                                                         Greenr   \n",
       "475                                                    Diving Deep   \n",
       "761                                       Join the Blue Revolution   \n",
       "763                                       Longwater Community Farm   \n",
       "877                                                   Stinger Surf   \n",
       "893         A NEW EXCITING ELECTRIC BICYCLE BRAND IN NORTH AMERICA   \n",
       "894       Eco Bin the worlds first Eco Friendly Sanitary/Nappy bin   \n",
       "1059   OS eBike: Open Source Electric Bicycle Design You Can Build   \n",
       "1130           \"The Sun Juicer\"  Ultralight Parabolic Solar Cooker   \n",
       "1192  Boulder Denim 3.0: Active jeans for work, play, and everyday   \n",
       "1267  TEA BAR- Vegan and Eco-Friendly health bar flavored with tea   \n",
       "1438                  Sustainable Produce For The Locals, Annually   \n",
       "1540                                     Fable: From Farm to Table   \n",
       "1601                        Low Cost Fresh & Finished Organic Food   \n",
       "1630                                                 Biobierwinkel   \n",
       "1654       Ellice Ruiz | Girlfriend Tested, Mother Nature Approved   \n",
       "1657             SJ family farm and ranch organic community garden   \n",
       "1666  Recycle Scrap Paper into Building Material - Papercrete Brix   \n",
       "1675                                    @SpeedingDonuts +Donutruck   \n",
       "1692                                                         Crude   \n",
       "1693  Young Scent - Premium Drinking Vinegar & Vinegar Concentrate   \n",
       "1710                          PIVOT | The Spray Bottle Reinvented.   \n",
       "1743                   Animal-Friendly Footwear Made Using Apples.   \n",
       "1766     Organic Soap that provides counseling for Foster children   \n",
       "1865                 DIFFAIR | Eco-Friendly Swiss Designer Fashion   \n",
       "1879                    Maushaus: Sustainable Desert Microdwelling   \n",
       "1905                  Endangered Animals: Africa Enamel Pin Series   \n",
       "1941                        Tiny House From Recycled Seacontainers   \n",
       "1946    Brooklyn Artists + Nature + Tee Shirts = Brooklyn Tee Time   \n",
       "\n",
       "                                                                                                                                        blurb  \\\n",
       "47                                                                  The first all in one highly eco-friendly tent made from recycled plastic.   \n",
       "71                    Delicious tea infusion made with seaweed. Healthy, organic, plant-based, eco-friendly, and rich-mineral tea for vegans.   \n",
       "99    Inspired by the selection at the Grocery mart, I want to make Safe Healthy Nutritious Slurpable foods for baby. No preservatives added.   \n",
       "125                            High fashions made from ethical and sustainable, environmentally friendly, vegan fabrics for the modern world.   \n",
       "163    A wood fired food truck & mobile farmers market that connects you to our farm, way of life and certified organic produce and products.   \n",
       "170                                               To create yarn&projects out of sustainable bamboo&hemp fiber with the desert dye cochineal.   \n",
       "233                                                           Buy a pair of our beautiful men's swim shorts and protect an endangered animal!   \n",
       "284        Small-batch simple syrups for bartending, mixology, coffee, cocktails, soda, chai, and more. Only organic and non-GMO ingredients.   \n",
       "331                                            An all natural and homemade dog treats that are personalized to every dog's needs and desires.   \n",
       "351           Redefining Henley fashion for women and men. Sustainably making the highest quality Henleys in the U.S.A. Be You. Be Confident.   \n",
       "380        A David and Goliath story about a Sydney community fighting to save hundreds of heritage trees from government-funded destruction.   \n",
       "398     A tool for a better farming in semi arid regions, in the context of climate change and based on experience in a Permaculture project.   \n",
       "474                       A company that tracks green behavior and rewards people with prizes in an effort to make the world a greener place!   \n",
       "475     Irrepressible underwater filmmaker Mike deGruy was adamant that we are destroying the ocean before we've discovered all that's there.   \n",
       "761                    Through education, sustainable agriculture and getting our hands dirty, we will work to build a better world together!   \n",
       "763   Growing our own food, caring for animals and the environment, providing education on healthy and sustainable living is what we do best!   \n",
       "877                            Stinger Surf Co. is an innovative brand that makes eco-friendly surf products and gives back to save the bees.   \n",
       "893                  Darrvin is an innovative e-bike design and build company, delivering exquisite hand-build precision and superior quality   \n",
       "894                              Worlds first Eco friendly Sanitary Bin that is biodegradable and 50% cheaper than a normal service provider.   \n",
       "1059          A guide for making a lightweight eBike design built with open source hardware and software you assemble and customize yourself.   \n",
       "1130        A sustainable fuel free, clean energy, 0 emissions way of cooking that is great for your backyard, camping, emergencies, and fun!   \n",
       "1192    Performance denim unlike anything you've worn before. Stretch, durability, breathability, and sustainability meet for the first time.   \n",
       "1267                        Organic, non-GMO, Eco-Friendly, Healthy, Super Food, Tasty, Vegan, Paleo, Keto.\\nCreated by a Chef and a Barista.   \n",
       "1438     A self-sustaining farm to feed locals fresh organic produce year round. Aquaponic system powered by wind and recycles all materials.   \n",
       "1540      Fable aims to be a year-round source for the freshest produce, all grown locally and without the use of GMOs or harmful pesticides.   \n",
       "1601          We are the First Vertical Integrated Organic Grower, Producer & Distribution company in Central America exporting into the USA.   \n",
       "1630       The first online 100% organic beer shop in the Netherlands. Bringing organic beers from small brewers from all over Europe to you.   \n",
       "1654                A sustainable & ethical ready-to-wear collection for creative professionals that transitions from the studio to the show.   \n",
       "1657          The goal of SJ farms is to provide healthy organic produce to our surrounding communities. And  to create a healthier tomorrow.   \n",
       "1666  Everyone loves to recycle, this project is about recycling common ordinary paper into building materials or decorative plain old bricks   \n",
       "1675                    Bringing healthy and organic eating to donut lovers from a locally supported family business! #donuts @speedingdonuts   \n",
       "1692                              A Campaign Film to raise awareness of the crude oil industry and the damage to the planet. Divest from oil.   \n",
       "1693                                                         All natural, handcrafted, organic fruit vinegars designed to vitalize your body.   \n",
       "1710                              Effortlessly spray at any angle. Use every drop without priming.  Save the earth from \"disposable\" culture!   \n",
       "1743                                            Crafted in Europe using sustainable innovative materials. A tree planted with each pair made.   \n",
       "1766                                       Organic soap that gives back to children effected by foster care by providing counseling services.   \n",
       "1865  An exclusive collection of affordable and sustainable designer clothing from our new type of fashion brand / Exklusive Designkollektion   \n",
       "1879                                   ASU Graduate Students must build a functional, sustainable mobile house of 100 square feet by May 1st!   \n",
       "1905                                                                                   A pin series raising awareness for endangered species.   \n",
       "1941                                                                      Tiny Houses - Small mobile houses made from recycled seacontainers!   \n",
       "1946      Roni & Dawn Henning, Brooklyn Artists and Printmakers create a Tee shirt company to raise awareness about the natural world at risk   \n",
       "\n",
       "     is_environmental  yes_count: is_envt  \\\n",
       "47                Yes                   3   \n",
       "71                Yes                   4   \n",
       "99                Yes                   4   \n",
       "125               Yes                   3   \n",
       "163               Yes                   4   \n",
       "170               Yes                   2   \n",
       "233               Yes                   1   \n",
       "284               Yes                   2   \n",
       "331               Yes                   1   \n",
       "351               Yes                   2   \n",
       "380               Yes                   0   \n",
       "398               Yes                   2   \n",
       "474               Yes                   2   \n",
       "475               Yes                   0   \n",
       "761               Yes                   3   \n",
       "763               Yes                   4   \n",
       "877               Yes                   3   \n",
       "893               Yes                   3   \n",
       "894               Yes                   7   \n",
       "1059              Yes                   4   \n",
       "1130              Yes                   1   \n",
       "1192              Yes                   1   \n",
       "1267              Yes                   7   \n",
       "1438              Yes                   5   \n",
       "1540              Yes                   1   \n",
       "1601              Yes                   3   \n",
       "1630              Yes                   2   \n",
       "1654              Yes                   2   \n",
       "1657              Yes                   5   \n",
       "1666              Yes                   5   \n",
       "1675              Yes                   2   \n",
       "1692              Yes                   0   \n",
       "1693              Yes                   3   \n",
       "1710              Yes                   0   \n",
       "1743              Yes                   2   \n",
       "1766              Yes                   2   \n",
       "1865              Yes                   5   \n",
       "1879              Yes                   3   \n",
       "1905              Yes                   0   \n",
       "1941              Yes                   2   \n",
       "1946              Yes                   3   \n",
       "\n",
       "                                          ranked_words  \n",
       "47                               [eco, friend, recycl]  \n",
       "71                       [healthi, organ, eco, friend]  \n",
       "99                         [food, make, healthi, food]  \n",
       "125                           [sustain, friend, world]  \n",
       "163                          [food, food, farm, organ]  \n",
       "170                                 [sustain, sustain]  \n",
       "233                                           [design]  \n",
       "284                                     [natur, organ]  \n",
       "331                                            [natur]  \n",
       "351                                    [sustain, make]  \n",
       "380                                                 []  \n",
       "398                                      [organ, farm]  \n",
       "474                                      [make, world]  \n",
       "475                                                 []  \n",
       "761                            [sustain, build, world]  \n",
       "763                     [farm, food, healthi, sustain]  \n",
       "877                                [make, eco, friend]  \n",
       "893                             [design, build, build]  \n",
       "894      [eco, world, eco, friend, world, eco, friend]  \n",
       "1059                     [design, build, make, design]  \n",
       "1130                                         [sustain]  \n",
       "1192                                         [sustain]  \n",
       "1267  [eco, friend, organ, eco, friend, healthi, food]  \n",
       "1438           [sustain, sustain, farm, organ, recycl]  \n",
       "1540                                            [farm]  \n",
       "1601                              [organ, food, organ]  \n",
       "1630                                    [organ, organ]  \n",
       "1654                                  [natur, sustain]  \n",
       "1657               [farm, organ, farm, healthi, organ]  \n",
       "1666            [recycl, build, recycl, recycl, build]  \n",
       "1675                                  [healthi, organ]  \n",
       "1692                                                []  \n",
       "1693                            [natur, organ, design]  \n",
       "1710                                                []  \n",
       "1743                                 [friend, sustain]  \n",
       "1766                                    [organ, organ]  \n",
       "1865            [eco, friend, design, sustain, design]  \n",
       "1879                         [sustain, build, sustain]  \n",
       "1905                                                []  \n",
       "1941                                  [recycl, recycl]  \n",
       "1946                             [natur, natur, world]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_envt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- Some of the terms identified (e.g. row:99->'food' row:233->'design') might not be relevant environmentally and may have to be removed from the list of ranked words. (How? -> More on this in sections below.)\n",
    "- The occurence of more than one different words or the same word multiple times from the list of ranked words in the samples increases the likelihood that the sample is correctly classified as relevant. We will later use this feature to our advantage.\n",
    "- Sample 233 is correctly classified, but due to the wrong reason! It found the word 'design' among the ranked word-list, but it should have been ideally 'endangered' which does not appear in our ranked words list. This again emphasizes the importance of more training data. The same can be said of the other incorrectly classified samples in the dataset. (More on how to circumvent this issue is discussed in later sections.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the same approach to samples marked as socially relevant. The results are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of identified top words distinguising socially relevant blurbs: 31\n",
      "Top words (is_social)\n",
      "-----------------------------\n",
      "communiti    0.121427\n",
      "support      0.114027\n",
      "project      0.078614\n",
      "build          0.0724\n",
      "free         0.069167\n",
      "covid         0.06393\n",
      "area         0.062197\n",
      "public       0.061306\n",
      "hous         0.060613\n",
      "card         0.059676\n",
      "rais         0.055751\n",
      "awar         0.055751\n",
      "make         0.054066\n",
      "shirt        0.052792\n",
      "live         0.051397\n",
      "school       0.049044\n",
      "help         0.047177\n",
      "fund         0.046626\n",
      "solut        0.045875\n",
      "film         0.044926\n",
      "know         0.041608\n",
      "fight        0.041572\n",
      "save         0.041075\n",
      "end            0.0406\n",
      "main         0.038005\n",
      "kid          0.036531\n",
      "app          0.036265\n",
      "children     0.033609\n",
      "individu     0.032786\n",
      "risk         0.032578\n",
      "creat        0.031378\n",
      "dtype: Sparse[float64, 0]\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------\n",
    "#2. FInd top ranking words in samples classified as social\n",
    "#----------------------------------------------------------------\n",
    "tf_idf_model = TfidfVectorizer(stop_words=STOP_WORDS, min_df= MIN_DOCS, token_pattern=TOKEN_PATTERN)\n",
    "\n",
    "blurb_is_social = df_is_envt_or_social[df_is_envt_or_social['is_social'] == 'Yes'][['campaign_name', 'blurb']].agg(' '.join, axis=1).tolist()\n",
    "blurb_is_social = stem([text.lower() for text in blurb_is_social])\n",
    "\n",
    "tf_idf_vector = tf_idf_model.fit_transform(blurb_is_social)\n",
    "words_set = tf_idf_model.get_feature_names_out()\n",
    "df_tf_idf = pd.DataFrame.sparse.from_spmatrix(tf_idf_vector, columns=words_set)\n",
    "word_importance = df_tf_idf.mean(axis=0)\n",
    "ranked_words_social = word_importance.sort_values(ascending=False)\n",
    "\n",
    "print(f'No. of identified top words distinguising socially relevant blurbs: {len(ranked_words_social)}')\n",
    "print('Top words (is_social)')\n",
    "print('-----------------------------')\n",
    "print(ranked_words_social)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on training data is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes_count: is_social\n",
      "at least one keyword    24\n",
      "No keyword               2\n",
      "Name: count, dtype: int64\n",
      "accuracy: 0.9231\n"
     ]
    }
   ],
   "source": [
    "df_social= df_is_envt_or_social[df_is_envt_or_social['is_social']=='Yes'].copy()\n",
    "df_social.drop('is_environmental',axis=1,inplace=True)\n",
    "\n",
    "rank_words(df_social, ranked_words_social, column_affirmative='yes_count: is_social')\n",
    "\n",
    "word_count_classified_social= get_word_count_in_classified_blurbs(df_social,'yes_count: is_social' )\n",
    "print(word_count_classified_social)\n",
    "print(f'accuracy: {word_count_classified_social.iloc[0]/(word_count_classified_social.iloc[0]+word_count_classified_social.iloc[1]):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now inspect the data frame in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign_name</th>\n",
       "      <th>blurb</th>\n",
       "      <th>is_social</th>\n",
       "      <th>yes_count: is_social</th>\n",
       "      <th>ranked_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Surviving the Unknown</td>\n",
       "      <td>A family struggles to survive off the grid in secrecy.  But it's more than just the harsh elements that are tearing them apart.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The Call - a voice to the voiceless</td>\n",
       "      <td>This is a project, which aims to save lives of unarmed men, women and children trapped in war, who reject to participate in violence!</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>[project, live]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Et al. Creatives</td>\n",
       "      <td>A collaborative employment, resource, and community platform.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>[communiti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>the breast express</td>\n",
       "      <td>pumpspotting is going cross-country to support &amp; show up for breastfeeding moms and document the boob-venture of a lifetime.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>[support]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Gay Occasions</td>\n",
       "      <td>I was looking in a card shop for a card for my fiancée, and was struck by the lack of LGBT cards available. Let's make it happen.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>[card, card, card, make]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>MIRZ PLAYING CARDS : 2ND EDITION (feat. Hope For Justice)</td>\n",
       "      <td>Change lives. End Slavery.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>[card, live]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Seattle Streets to Main Street: End Child Trafficking.</td>\n",
       "      <td>Help me build the social impact of my award winning documentary “The Long Night” and get the film to audiences everywhere.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>[build]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>MizaBella After School Project</td>\n",
       "      <td>Teaching Kids How To Knit</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>[project]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Aegis</td>\n",
       "      <td>Aegis- A turnkey security solution that scans the area for security threats and risks to safeguard public health w.r.t Covid-19</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>[area, public, covid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>Little Free Library in West Louisville, Kentucky</td>\n",
       "      <td>Support the creation of a little free library in West Louisville, Kentucky.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>[free, support, free]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Tree Rally</td>\n",
       "      <td>A David and Goliath story about a Sydney community fighting to save hundreds of heritage trees from government-funded destruction.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>[communiti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>The French Quarter Parklet</td>\n",
       "      <td>We're building a public parklet on 21st at Main. This project adds a bike bar and a community art wall.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>[build, public, project, communiti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>The Veterans Daily Journal</td>\n",
       "      <td>We would like to raise public awareness of individual veterans that have fallen through the cracks of the system. Creating a community.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>[rais, public, awar, communiti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>Lights in the Clouds</td>\n",
       "      <td>College students numb themselves with drugs, sex, alcohol, etc. Our film will examine the consequences to these temporary solutions.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>LinQupp</td>\n",
       "      <td>I am developing an app dedicated to those on the front lines medical to support staff fighting to combat Covid-19. Thank you all!!</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>[support, covid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>FREE! Fitness for all</td>\n",
       "      <td>A public area for everyone to keep fit and healthy and all 100% FREE to use!</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>[free, public, area, free]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>Bring Know Orchestra to Boston Area Kids</td>\n",
       "      <td>With your support, Know Orchestra is seeking to bring its interactive and educational live show to children in underserved communities.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>[area, support, live, communiti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>Learning Gardens Reader Launch</td>\n",
       "      <td>Stylish booklet to celebrate decentralized learning through community building. Funds will go towards our grants program!</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>[communiti, build]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>ComfPort: Clothing With A Cause - Making Cancer Comfortable</td>\n",
       "      <td>Fashion forward clothing that is designed for cancer patients and their supporters. 1 shirt purchased = 1 donated to a cancer patient!</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>[make, support, shirt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>Covid-19 Helper</td>\n",
       "      <td>An app that explains everything about Covid-19 and does contact tracing for individuals that don't want people to know who they are...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>[covid, covid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>Chicagoland Soccer</td>\n",
       "      <td>Support high school boys soccer\\ncoverage in the Chicagoland area.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>[support, area]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>Endangered Animals: Africa Enamel Pin Series</td>\n",
       "      <td>A pin series raising awareness for endangered species.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>[rais, awar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>Make a Home for SweetRoot Farm</td>\n",
       "      <td>House the farmers at SweetRoot in a cozy yurt so we can continue to focus on building our farm and feeding our community.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>[make, hous, build, communiti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>(Pet-A-Tree), \"where every pet deserves a pedigree\".</td>\n",
       "      <td>Project (Pet-A-Tree) is a humanitarian based forest of information branching outward to help bridge the gap between pet and parent.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>[project]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>Tiny House From Recycled Seacontainers</td>\n",
       "      <td>Tiny Houses - Small mobile houses made from recycled seacontainers!</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>[hous, hous, hous]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>Brooklyn Artists + Nature + Tee Shirts = Brooklyn Tee Time</td>\n",
       "      <td>Roni &amp; Dawn Henning, Brooklyn Artists and Printmakers create a Tee shirt company to raise awareness about the natural world at risk</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>[shirt, shirt, rais, awar]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    campaign_name  \\\n",
       "6                                           Surviving the Unknown   \n",
       "23                            The Call - a voice to the voiceless   \n",
       "55                                               Et al. Creatives   \n",
       "63                                             the breast express   \n",
       "88                                                  Gay Occasions   \n",
       "100     MIRZ PLAYING CARDS : 2ND EDITION (feat. Hope For Justice)   \n",
       "130        Seattle Streets to Main Street: End Child Trafficking.   \n",
       "150                                MizaBella After School Project   \n",
       "210                                                         Aegis   \n",
       "371              Little Free Library in West Louisville, Kentucky   \n",
       "380                                                    Tree Rally   \n",
       "390                                    The French Quarter Parklet   \n",
       "393                                    The Veterans Daily Journal   \n",
       "394                                          Lights in the Clouds   \n",
       "555                                                       LinQupp   \n",
       "578                                         FREE! Fitness for all   \n",
       "775                      Bring Know Orchestra to Boston Area Kids   \n",
       "884                                Learning Gardens Reader Launch   \n",
       "1016  ComfPort: Clothing With A Cause - Making Cancer Comfortable   \n",
       "1146                                              Covid-19 Helper   \n",
       "1901                                           Chicagoland Soccer   \n",
       "1905                 Endangered Animals: Africa Enamel Pin Series   \n",
       "1929                               Make a Home for SweetRoot Farm   \n",
       "1939         (Pet-A-Tree), \"where every pet deserves a pedigree\".   \n",
       "1941                       Tiny House From Recycled Seacontainers   \n",
       "1946   Brooklyn Artists + Nature + Tee Shirts = Brooklyn Tee Time   \n",
       "\n",
       "                                                                                                                                        blurb  \\\n",
       "6             A family struggles to survive off the grid in secrecy.  But it's more than just the harsh elements that are tearing them apart.   \n",
       "23      This is a project, which aims to save lives of unarmed men, women and children trapped in war, who reject to participate in violence!   \n",
       "55                                                                             A collaborative employment, resource, and community platform.    \n",
       "63               pumpspotting is going cross-country to support & show up for breastfeeding moms and document the boob-venture of a lifetime.   \n",
       "88          I was looking in a card shop for a card for my fiancée, and was struck by the lack of LGBT cards available. Let's make it happen.   \n",
       "100                                                                                                                Change lives. End Slavery.   \n",
       "130                Help me build the social impact of my award winning documentary “The Long Night” and get the film to audiences everywhere.   \n",
       "150                                                                                                                 Teaching Kids How To Knit   \n",
       "210           Aegis- A turnkey security solution that scans the area for security threats and risks to safeguard public health w.r.t Covid-19   \n",
       "371                                                               Support the creation of a little free library in West Louisville, Kentucky.   \n",
       "380        A David and Goliath story about a Sydney community fighting to save hundreds of heritage trees from government-funded destruction.   \n",
       "390                                   We're building a public parklet on 21st at Main. This project adds a bike bar and a community art wall.   \n",
       "393   We would like to raise public awareness of individual veterans that have fallen through the cracks of the system. Creating a community.   \n",
       "394      College students numb themselves with drugs, sex, alcohol, etc. Our film will examine the consequences to these temporary solutions.   \n",
       "555        I am developing an app dedicated to those on the front lines medical to support staff fighting to combat Covid-19. Thank you all!!   \n",
       "578                                                              A public area for everyone to keep fit and healthy and all 100% FREE to use!   \n",
       "775   With your support, Know Orchestra is seeking to bring its interactive and educational live show to children in underserved communities.   \n",
       "884                 Stylish booklet to celebrate decentralized learning through community building. Funds will go towards our grants program!   \n",
       "1016   Fashion forward clothing that is designed for cancer patients and their supporters. 1 shirt purchased = 1 donated to a cancer patient!   \n",
       "1146   An app that explains everything about Covid-19 and does contact tracing for individuals that don't want people to know who they are...   \n",
       "1901                                                                       Support high school boys soccer\\ncoverage in the Chicagoland area.   \n",
       "1905                                                                                   A pin series raising awareness for endangered species.   \n",
       "1929                House the farmers at SweetRoot in a cozy yurt so we can continue to focus on building our farm and feeding our community.   \n",
       "1939      Project (Pet-A-Tree) is a humanitarian based forest of information branching outward to help bridge the gap between pet and parent.   \n",
       "1941                                                                      Tiny Houses - Small mobile houses made from recycled seacontainers!   \n",
       "1946      Roni & Dawn Henning, Brooklyn Artists and Printmakers create a Tee shirt company to raise awareness about the natural world at risk   \n",
       "\n",
       "     is_social  yes_count: is_social                         ranked_words  \n",
       "6          Yes                     0                                   []  \n",
       "23         Yes                     2                      [project, live]  \n",
       "55         Yes                     1                          [communiti]  \n",
       "63         Yes                     1                            [support]  \n",
       "88         Yes                     4             [card, card, card, make]  \n",
       "100        Yes                     2                         [card, live]  \n",
       "130        Yes                     1                              [build]  \n",
       "150        Yes                     1                            [project]  \n",
       "210        Yes                     3                [area, public, covid]  \n",
       "371        Yes                     3                [free, support, free]  \n",
       "380        Yes                     1                          [communiti]  \n",
       "390        Yes                     4  [build, public, project, communiti]  \n",
       "393        Yes                     4      [rais, public, awar, communiti]  \n",
       "394        Yes                     0                                   []  \n",
       "555        Yes                     2                     [support, covid]  \n",
       "578        Yes                     4           [free, public, area, free]  \n",
       "775        Yes                     4     [area, support, live, communiti]  \n",
       "884        Yes                     2                   [communiti, build]  \n",
       "1016       Yes                     3               [make, support, shirt]  \n",
       "1146       Yes                     2                       [covid, covid]  \n",
       "1901       Yes                     2                      [support, area]  \n",
       "1905       Yes                     2                         [rais, awar]  \n",
       "1929       Yes                     4       [make, hous, build, communiti]  \n",
       "1939       Yes                     1                            [project]  \n",
       "1941       Yes                     3                   [hous, hous, hous]  \n",
       "1946       Yes                     4           [shirt, shirt, rais, awar]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_social"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- The observations we made in the case of environmentally relevant samples are more or less valid in the case of socially relevant samples also.\n",
    "- Row:100 is interesting. It is correctly classified, but is is questionable that the words ('card') are really relevant (Emphasis on more traing data!). It is also questionabl if the manual curation is also correct in this case, since´the project is about playing cards. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we also try to get the most ranked words list taking the data frame as a whole. The least overlap in this list of words with other ranked word lists will confirm that the top ranked words list corresponding to each topic is indeed distinct and represents the particular topic it is assigned to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of identified top words in all blurbs: 12\n",
      "Top words (all)\n",
      "-----------------------------\n",
      "new         0.08107\n",
      "help       0.077095\n",
      "book       0.062207\n",
      "make       0.057526\n",
      "film       0.057032\n",
      "world      0.056284\n",
      "art        0.053833\n",
      "creat      0.053278\n",
      "album      0.051541\n",
      "music       0.05118\n",
      "project    0.045769\n",
      "need       0.036496\n",
      "dtype: Sparse[float64, 0]\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------\n",
    "#3. Find top ranking words in all samples, for the sake of completeness\n",
    "#----------------------------------------------------------------\n",
    "tf_idf_model = TfidfVectorizer(stop_words=STOP_WORDS, min_df= .05)\n",
    "\n",
    "blurb_all = df[['campaign_name', 'blurb']].agg(' '.join, axis=1).tolist()\n",
    "blurb_all = stem([text.lower() for text in blurb_all])\n",
    "\n",
    "tf_idf_vector = tf_idf_model.fit_transform(blurb_all)\n",
    "words_set = tf_idf_model.get_feature_names_out()\n",
    "df_tf_idf = pd.DataFrame.sparse.from_spmatrix(tf_idf_vector, columns=words_set)\n",
    "word_importance = df_tf_idf.mean(axis=0)\n",
    "ranked_words = word_importance.sort_values(ascending=False)\n",
    "print(f'No. of identified top words in all blurbs: {len(ranked_words)}')\n",
    "print('Top words (all)')\n",
    "print('-----------------------------')\n",
    "print(ranked_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the top ranked words in the entire dataset is different from the other words list we derived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "common_words_social_environment = set(ranked_words_social.head(5).index) & set(ranked_words_environmental.head(5).index)\n",
    "print(common_words_social_environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Attention!\n",
    "--- -------------------\n",
    "Some of the important parameters in the tf-idf algotithm relevant to our analysis are:\n",
    "1.  **min-df:**\n",
    "\n",
    "    This is the minimum number of documents in which the word should appear, in order for it to be considered relevant. To ideally represent a topic, the min-df should be large. However, we have only very little training data (~50 for environmentally relevant and ~25 for socially relevant) and we run to the risk of losing information with a higher min_df value. We initially set it at 0.05%- this means, an term that appears in fewer than 5% of the documents (~2 documents) will be ignored and not considered for analysis. This emphasizes the importance of having more training data.\n",
    "\n",
    "    Please see the <a. illustartion: min_df= 0.1> in the section below.\n",
    "\n",
    "2. **mean tf-idf score:**\n",
    "    It is possible to set a minimum threshold score value so that words with scores below the threshold in the ranked word list are not considered for analysis. In the analyses above, the default value is 0.05. \n",
    "\n",
    "    please see the <b. Illustration: tf_df_threshold= 0.06> in the section below.\n",
    "3. **words_num_threshold:**\n",
    "    We saw from the previous sections that the more nummber of times different words appear in the extract, the stronger the categorisation is. In order for us to do this, we need to increase the confidence in the selected list of words. \n",
    "\n",
    "Other methods to improve confidence:\n",
    "- **Stemmimng and Lemmatization:** \n",
    "\n",
    "    We saw stemming in a previous section. We could also experiment with ['lemmatization'](https://www.ibm.com/topics/stemming-lemmatization?mhsrc=ibmsearch_a&mhq=lemmatization) and various combinations of both to try to improve the performance.\n",
    "- **manual pruning of words:** \n",
    "\n",
    "    We saw in the previous sections that (due to insufficient training data) some top ranked words might not be relevant in the domain of investigation, afterall. (e.g.'card' in socially relevant topics.) It is worth a try to manually prune the ranked words list and remove irrelevant words.\n",
    "- **Manual inclusion of words:** \n",
    "\n",
    "    Similarly, it is also recommended to include words which might be relevant to the topic. For example, words such as 'tree', 'endangered', 'eBike' etc. might be relevant to environmental projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. Illustration: min_df= 0.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df= 0.1\n",
      "No. of identified top words distinguising environmentally relevant blurbs: 13.\n",
      "\n",
      "The first column represents the relevant words and the second column gives the mean tf-idf score\n",
      "We see stronger tf-idf scores, but lower number of terms which will have an effect on categorization.This means that there are fewer, but surer terms which indicate if the sample is relevant or not.\n",
      "\n",
      "Top words (is_environmental)\n",
      "-----------------------------\n",
      "sustain    0.191448\n",
      "organ      0.164938\n",
      "friend     0.107089\n",
      "natur      0.100755\n",
      "design     0.090118\n",
      "eco        0.087987\n",
      "build      0.085141\n",
      "farm       0.082849\n",
      "food       0.072712\n",
      "world      0.072143\n",
      "make       0.071882\n",
      "healthi    0.070624\n",
      "produc     0.065731\n",
      "dtype: Sparse[float64, 0]\n"
     ]
    }
   ],
   "source": [
    "tf_idf_model = TfidfVectorizer(stop_words=STOP_WORDS, min_df= .1, token_pattern=TOKEN_PATTERN)\n",
    "\n",
    "#blurb_is_environmental= df_is_envt_or_social[df_is_envt_or_social['is_environmental'] == 'Yes']['blurb'].tolist()\n",
    "blurb_demo = df_is_envt_or_social[df_is_envt_or_social['is_environmental'] == 'Yes'][['campaign_name', 'blurb']].agg(' '.join, axis=1).tolist()\n",
    "blurb_demo = stem([text.lower() for text in blurb_demo])\n",
    "\n",
    "#Vectorization of corpus\n",
    "tf_idf_vector = tf_idf_model.fit_transform(blurb_demo)\n",
    "\n",
    "# #Get original terms in the corpus\n",
    "words_set = tf_idf_model.get_feature_names_out()\n",
    "\n",
    "# #Data frame to show the TF-IDF scores of each document\n",
    "df_tf_idf = pd.DataFrame.sparse.from_spmatrix(tf_idf_vector, columns=words_set)\n",
    "\n",
    "# Calculate the sum of TF-IDF scores for each word\n",
    "word_importance = df_tf_idf.mean(axis=0)\n",
    "\n",
    "# Sort words based on the sum of TF-IDF scores\n",
    "ranked_words_demo = word_importance.sort_values(ascending=False)\n",
    "\n",
    "# Print the ranked words\n",
    "print('min_df= 0.1')\n",
    "print(f'''No. of identified top words distinguising environmentally relevant blurbs: {len(ranked_words_demo)}.\\n\n",
    "The first column represents the relevant words and the second column gives the mean tf-idf score''')\n",
    "print('''We see stronger tf-idf scores, but lower number of terms which will have an effect on categorization.\\\n",
    "This means that there are fewer, but surer terms which indicate if the sample is relevant or not.''')\n",
    "print()\n",
    "print('Top words (is_environmental)')\n",
    "print('-----------------------------')\n",
    "print(ranked_words_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Illustration: tf_df_threshold= 0.06**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorization summary\n",
      "========================\n",
      "yes_count: is_envt\n",
      "at least one keyword    33\n",
      "No keyword               8\n",
      "Name: count, dtype: int64\n",
      "accuracy: 0.8049\n"
     ]
    }
   ],
   "source": [
    "df_envt_demo= df_is_envt_or_social[df_is_envt_or_social['is_environmental']=='Yes'].copy()\n",
    "df_envt_demo.drop('is_social',axis=1,inplace=True)\n",
    "rank_words(df_envt_demo, ranked_words_environmental, column_affirmative='yes_count: is_envt',threshold=0.06)\n",
    "word_count_classified_envt_demo= get_word_count_in_classified_blurbs(df_envt_demo,'yes_count: is_envt' )\n",
    "print('Categorization summary')\n",
    "print('========================')\n",
    "print(word_count_classified_envt_demo)\n",
    "print(f'accuracy: {word_count_classified_envt_demo.iloc[0]/(word_count_classified_envt_demo.iloc[0]+word_count_classified_envt_demo.iloc[1]):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the accuracy has dropped, because understandably there are only a lower number of terms now available for categorization. But this is not necessarily bad! it is quite possible that we were overfitting on the training data and the model might not work quite as expected on data it has not seen before. Therefore, it is again good to have more training data, so that we can increase the threshold confidemntly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Categorize the dataframe\n",
    "--- -------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the selected words list to categorize the whole data frame as socially or environmentally relevant. The parameters are kept their default values mentioned in the previous sections. The words_num_threshold is kept as 2, meaning that atleast 2 occurences of the same word or different word should exist in order for the extract to be categorized into the repective category. The manually curated samples are NOT overwritten, irrespective of the resulting relevant word counts for these samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_write= df.copy()\n",
    "df_to_write.drop(columns=['sub_category', 'country', 'duration_in_days', 'goal_usd', 'pledged_amount_usd'], axis= 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_curated= df_to_write[df_to_write['is_social']!='unspecified'].copy()\n",
    "\n",
    "df_curated= rank_words(df_curated, ranked_words_environmental, 'count_is_envt', column_ranked_words='ranked_words_envt', threshold=0.05)\n",
    "df_curated= rank_words(df_curated, ranked_words_social, 'count_is_social', column_ranked_words='ranked_words_social', threshold=0.05)\n",
    "df_curated.drop(columns=['count_is_social', 'count_is_envt'],axis=1, inplace=True)\n",
    "\n",
    "df_uncategorized= df_to_write.loc[df_to_write['is_social']=='unspecified'].copy()\n",
    "df_uncategorized= rank_words(df_uncategorized, ranked_words_environmental, 'count_is_envt', column_ranked_words='ranked_words_envt', threshold=0.05)\n",
    "df_uncategorized= rank_words(df_uncategorized, ranked_words_social, 'count_is_social', column_ranked_words='ranked_words_social', threshold=0.05)\n",
    "\n",
    "df_uncategorized['is_environmental'] = np.where(df_uncategorized['count_is_envt'] >= 2, 'Yes', 'No')\n",
    "df_uncategorized['is_social'] = np.where(df_uncategorized['count_is_social'] >= 2, 'Yes', 'No')\n",
    "df_uncategorized.drop(columns=['count_is_social', 'count_is_envt'],axis=1, inplace=True)\n",
    "\n",
    "df_categorized= pd.concat([df_curated, df_uncategorized])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the processed data\n",
    "#df_categorized.dropna(how='all', inplace=True)\n",
    "#df_categorized.to_csv('./data/dataframe_categorized.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After saving the data, we look at some metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples marked as environmentally relevant: 11450; i.e, 7.097 % of total samples\n",
      "Number of samples marked as socially relevant: 13914; i.e, 8.624 % of total samples\n",
      "Number of samples marked as success: 93189; i.e, 57.757 % of total samples\n",
      "Number of environmentally successful samples: 5192; i.e, 3.218 % of total samples\n",
      "Number of environmentally successful samples: 8006; i.e, 4.962 % of total samples\n"
     ]
    }
   ],
   "source": [
    "shape_envt= df_categorized[df_categorized['is_environmental']=='Yes'].shape\n",
    "print(f'Number of samples marked as environmentally relevant: {shape_envt[0]}; i.e, {(shape_envt[0] *100/df_categorized.shape[0]):2.3f} % of total samples')\n",
    "\n",
    "shape_social= df_categorized[df_categorized['is_social']=='Yes'].shape\n",
    "print(f'Number of samples marked as socially relevant: {shape_social[0]}; i.e, {(shape_social[0] *100/df_categorized.shape[0]):2.3f} % of total samples')\n",
    "\n",
    "shape_success= df_categorized[df_categorized['is_success']=='successful'].shape\n",
    "print(f'Number of samples marked as success: {shape_success[0]}; i.e, {(shape_success[0] *100/df_categorized.shape[0]):2.3f} % of total samples')\n",
    "\n",
    "shape_envt_success= df_categorized[(df_categorized['is_success']=='successful') & (df_categorized['is_environmental']=='Yes')].shape\n",
    "print(f'Number of environmentally successful samples: {shape_envt_success[0]}; i.e, {(shape_envt_success[0] *100/df_categorized.shape[0]):2.3f} % of total samples')\n",
    "\n",
    "\n",
    "shape_social_success= df_categorized[(df_categorized['is_success']=='successful') & (df_categorized['is_social']=='Yes')].shape\n",
    "print(f'Number of environmentally successful samples: {shape_social_success[0]}; i.e, {(shape_social_success[0] *100/df_categorized.shape[0]):2.3f} % of total samples')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please also note that the data can of course contain false positives and false negatives. These can be reduced by suitably adjusting the parameters mentioned in the previous sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. To Dos\n",
    "--- -------------------\n",
    "- Critically analyze the findings of this notebook. Try different combinations of the suggested parameters and evaluate results.\n",
    "- Critically analyze the categorized dataframe\n",
    "- Manually enrich the training data as suggested in the previous sections and see if it brings out better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pivot:\n",
    "    - summarize success to funding goal\n",
    "    - categories \n",
    "\n",
    "\n",
    "    ##To do:\n",
    "pie chart of :\n",
    "- success categories\n",
    "- goal usd_categories\n",
    "- main categores\n",
    "- sub categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter nbconvert --to HTML 02.Dataset_semantic_analysis.ipynb --no-input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
